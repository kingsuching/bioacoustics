{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d741ee77-42a8-48ef-8b81-cbcf926ff9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.utils.io import capture_output\n",
    "with capture_output() as captured:\n",
    "    ! pip install import_ipynb\n",
    "    ! pip install tensorflow==2.15.0\n",
    "    ! pip install boto3\n",
    "    ! pip install pandas\n",
    "    ! pip install librosa\n",
    "    ! pip install soundfile\n",
    "    ! pip install opencv-contrib-python\n",
    "    ! pip install tensorflow_probability==0.23.0\n",
    "    ! pip install scikit-maad\n",
    "    ! pip install tensorflow_addons==0.23.0\n",
    "    ! pip install wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88056f75-a03b-4372-90a8-64cdbd8e516d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 20:02:46.498186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-07 20:02:46.498223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-07 20:02:46.499584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-07 20:02:46.507264: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-07 20:02:47.356608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-07 20:02:49.245427: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.utils.io import capture_output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "sys.path.append('/opt/anaconda3/lib/python3.11/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.layers import Dense, Lambda\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from PIL import ImageColor, ImageFont\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pdb\n",
    "import glob\n",
    "import cv2\n",
    "import boto3\n",
    "import wave\n",
    "from tqdm import tqdm\n",
    "import import_ipynb\n",
    "import os\n",
    "import re\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78e7ca8-dbf2-4676-bd0a-d82e861fb0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preprocessing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def awsKeys(file):\n",
    "    awsKeys = pd.read_csv(file)\n",
    "    access_key = awsKeys['Access key ID'][0]\n",
    "    secret_key = awsKeys['Secret access key'][0]\n",
    "    return access_key, secret_key\n",
    "\n",
    "def clientAndBucket(file, region = 'us-west-2'):\n",
    "    aws_access_key_id, aws_secret_access_key = awsKeys(file)\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=region\n",
    "    )\n",
    "    bucket_name = 'whale-recordings'\n",
    "    s3 = boto3.resource('s3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=region\n",
    "    )\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    return s3_client, bucket\n",
    "\n",
    "KEYS = \"ssundar_accessKeys.csv\"\n",
    "s3_client, bucket = clientAndBucket(KEYS)\n",
    "\n",
    "%run model_functions_mel.ipynb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# List to store processed data\n",
    "processed_data = []\n",
    "D2 = []\n",
    "backgroundFiles = []\n",
    "\n",
    "path = \"CPhydrophone/Avila/Deployment 2/selection-tables/\"\n",
    "\n",
    "keys = [obj.key for obj in bucket.objects.all()]\n",
    "selectionTables = [(obj.split(\"/\")[-1], obj) for obj in keys if path in obj][1:]\n",
    "len(selectionTables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d4d15-ee13-492b-a154-33972d8fe5bc",
   "metadata": {},
   "source": [
    "## when doing predictions do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061dfb59-701d-41c0-8dc7-1f3ee8ba0516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%run model_functions_mel.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046ad6ad-aa8a-47c7-9859-358890fb176f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_and_concat_arrays(arrays, pad_value=0):\n",
    "    # Find the length of the longest array\n",
    "    max_length = max(len(arr) for arr in arrays)\n",
    "\n",
    "    # Pad each array and store it in a new list\n",
    "    padded_arrays = [np.pad(arr, (0, max_length - len(arr)), 'constant', constant_values=pad_value) for arr in arrays]\n",
    "\n",
    "    # Concatenate the padded arrays\n",
    "    concatenated_array = np.concatenate(padded_arrays, axis=0)\n",
    "\n",
    "    return concatenated_array\n",
    "\n",
    "def exclude(audio_file, labels_file, filtered_filename=\"concatenatedTrainingData.wav\"):\n",
    "    # Load audio file\n",
    "    y, sr = sf.read(audio_file,dtype=\"float32\")\n",
    "\n",
    "    # Load labels file as pandas dataframe\n",
    "    df = pd.read_csv(labels_file, delimiter='\\t')\n",
    "\n",
    "    # Convert start and end times to sample indices\n",
    "    start_idx = librosa.time_to_samples(df['Begin Time (s)'], sr=sr)\n",
    "    end_idx = librosa.time_to_samples(df['End Time (s)'], sr=sr)\n",
    "\n",
    "    # Create a boolean mask for each frame\n",
    "    frames = librosa.util.frame(y, frame_length=sr, hop_length=sr).T\n",
    "    mask = np.ones(frames.shape[0], dtype=bool)\n",
    "\n",
    "    # Loop over each interval and exclude corresponding frames\n",
    "    for idx in range(len(start_idx)):\n",
    "        start_frame = start_idx[idx] // sr\n",
    "        end_frame = end_idx[idx] // sr\n",
    "        mask[start_frame:end_frame+1] = False\n",
    "\n",
    "    # Apply mask to frames\n",
    "    frames_filtered = frames[mask]\n",
    "\n",
    "    # Reshape filtered frames into audio signal\n",
    "    y_filtered = frames_filtered.reshape(-1)\n",
    "    sf.write(filtered_filename, y_filtered, sr)\n",
    "    return sr, y_filtered\n",
    "\n",
    "def train_model_notebook(train_dataset,path=None, epochs=5):\n",
    "    segments=1\n",
    "    latent_dim=2000\n",
    "    vae=build_model(latent_dim,None)\n",
    "    vae.fit(train_dataset, epochs=epochs)\n",
    "    if path is not None:\n",
    "        # Save model weights to a file\n",
    "        vae.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0ca991-2841-401c-83b1-7bc444065a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ENDING = 'processed.wav'\n",
    "class VAEnsemble:\n",
    "    \"\"\"Assumes the vae_loss_function and error_dataset and run_model functions and write_array_to_file are defined in the model_functions.ipynb file\"\"\"\n",
    "    def __init__(self, filePath = \".\", n = 10, trainSplit=0.80, epochs=5):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param filePath: path to decimated wav files\n",
    "        :param n: number of units in ensemble\n",
    "        :param trainSplit: train/test split percentage\n",
    "        :param epochs: number of epochs\n",
    "        \"\"\"\n",
    "        self.filePath = filePath # path to the files\n",
    "        self.n = n\n",
    "        self.files = os.listdir(filePath)\n",
    "        self.files = [file for file in self.files if file.endswith(\"-SS.txt\") or file.endswith(\".wav\")]\n",
    "        self.folders = []\n",
    "        self.finished = False\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def splitData(self):\n",
    "        \"\"\"\n",
    "        Splits the data into n parts\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # split data into n parts for model training\n",
    "        stuff = [f for f in self.files if f.endswith(\"-SS.txt\")]\n",
    "        return np.array_split(stuff, self.n)\n",
    "    \n",
    "    def concatenate_wav_files(self, prefix, wav_files, output_file):\n",
    "        \"\"\"Concatenate multiple wav files into a single wav file.\n",
    "        :param prefix: The directory containing the wav files.\n",
    "        :param wav_files: A list of wav file names.\n",
    "        :param output_file: The name of the output file.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open the first wav file\n",
    "        with wave.open(f'{prefix}/{wav_files[0]}', 'rb') as wf:\n",
    "            params = wf.getparams()\n",
    "            frames = wf.readframes(wf.getnframes())\n",
    "\n",
    "        # Create a new wav file\n",
    "        with wave.open(output_file, 'wb') as output:\n",
    "            output.setparams(params)\n",
    "            output.writeframes(frames)\n",
    "\n",
    "            # Iterate over the rest of the wav files\n",
    "            for file in wav_files[1:]:\n",
    "                with wave.open(f'{prefix}/{file}', 'rb') as wf:\n",
    "                    frames = wf.readframes(wf.getnframes())\n",
    "                    output.writeframes(frames)\n",
    "    \n",
    "    def trainEnsembles(self, check=True):\n",
    "        \"\"\"\n",
    "        Trains the ensemble\n",
    "        :param check: check if the models are already trained\n",
    "        :return: None, writes model weights to directories\n",
    "        \"\"\"\n",
    "        splits = self.splitData()\n",
    "        i = 1\n",
    "        j = 1\n",
    "        if check and self.folders != []:\n",
    "            print(\"Already trained\")\n",
    "            return\n",
    "        self.folders = []\n",
    "        for data in tqdm(splits):\n",
    "            j = 1\n",
    "            path = f\"test_vae_ensemble_mod_pcen_mel_{i}\"\n",
    "            self.folders.append(path)\n",
    "            if check and os.path.exists(path):\n",
    "                i += 1\n",
    "                continue\n",
    "            print(f\"Building model {i}\")\n",
    "            wavFiles = [f'{i.replace(\"-SS.txt\", \"\")}_{ENDING}' for i in data if \"-SS.txt\" in i]\n",
    "            \n",
    "            #print(wavFiles)\n",
    "            outPath = f'files/backgroundNoiseSplit{i}'\n",
    "            self.concatenate_wav_files('files', wavFiles, outPath)\n",
    "            everythingSS = pd.DataFrame()\n",
    "            for ss in data:\n",
    "                if \"-SS.txt\" in ss:\n",
    "                    df = pd.read_csv(f'files/{ss}', sep = '\\t')\n",
    "                    everythingSS = pd.concat([everythingSS, df])\n",
    "            everythingSS.to_csv(f'{outPath}_SS.txt', sep = '\\t', index = False)\n",
    "            background_noise = exclude(outPath, labels_file=f'{outPath}_SS.txt', filtered_filename=f'{outPath}.wav')[1]\n",
    "            \n",
    "            dataset_train,sr = process_wav(f'{outPath}.wav', running = True)\n",
    "            train_model_notebook(dataset_train, path, epochs=self.epochs)\n",
    "            i += 1\n",
    "            self.finished = len(self.folders) == self.n\n",
    "            \n",
    "    def predict(self, predictingFile, folder=\"predictions\"):\n",
    "        \"\"\"Use trained VAE models to predict on new audio data.\n",
    "        \n",
    "        :param predictingFile: The file to predict on.\n",
    "        :return predictions: A pandas dataframe containing the predictions.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # make a directory for the predictions\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        dataset_test, sr = process_wav(predictingFile, running = True)\n",
    "        everything = pd.DataFrame()\n",
    "        for path in tqdm(self.folders):\n",
    "            try:\n",
    "                vae=keras.models.load_model(path, custom_objects={\"vae_loss_function\": vae_loss_function})\n",
    "                non_normal_scores=error_dataset(vae,dataset_test,False,sr=sr) # len > 0\n",
    "                bounding_boxes=run_model(non_normal_scores)\n",
    "                print(len(bounding_boxes))\n",
    "                titles=[\"Begin Time (s)\",\"End Time (s)\",\"Low Freq (Hz)\",\"High Freq (Hz)\",\"Species confidence\"]\n",
    "                write_array_to_file(bounding_boxes,titles,predictingFile.split('_')[0] + \"_predictions.txt\")\n",
    "                predictions = pd.read_csv(predictingFile.split('_')[0] + \"_predictions.txt\", sep = '\\t')\n",
    "                predictions['model'] = path\n",
    "                everything = pd.concat([everything, predictions])\n",
    "            except:\n",
    "                print(\"Could not do it for model\", path)\n",
    "                continue\n",
    "        # group by the path and take the mean of the predictions\n",
    "        numbers = re.search(r'\\d+\\.\\d+', predictingFile).group()\n",
    "        everything.reset_index(drop=True, inplace=True)\n",
    "        print(\"writing to\", f\"{folder}/{numbers}_predictions.txt\")\n",
    "        everything.to_csv(f\"{folder}/{numbers}_predictions.txt\", sep = \"\\t\", index=False) # in case the bottom doesn't work"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test the VAE Ensemble",
   "id": "1a2d33136b741c25"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3536345-6256-4ef9-8210-b3d4b113850b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already trained\n"
     ]
    }
   ],
   "source": [
    "vae = VAEnsemble(\"files\", epochs=20)\n",
    "vae.folders = [f for f in os.listdir() if \"test_vae_ensemble_mod_pcen_mel_\" in f]\n",
    "vae.trainEnsembles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba97820-f61d-4bdc-b464-b34cd43d88cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6805.230204210826_processed.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = [f for f in os.listdir('files') if f.endswith('_processed.wav')][0]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bd0be0-b2e5-4534-a75e-2ced4f74c191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae.predict('files/6805.230204210826_processed.wav', folder=\"predictions_mel\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate predictions for all 39 files",
   "id": "48e2217bf706a8ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e176b02-8c3a-4a51-87c5-b4a098a34360",
   "metadata": {
    "tags": [
     "predictions"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 of 39 files done\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe46196c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbb746d5a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "predictionsFiles = [os.path.join('files', f) for f in os.listdir('files') if f.endswith('_processed.wav')]\n",
    "\n",
    "count = 0\n",
    "for file in tqdm(predictionsFiles):\n",
    "    numbers = file.split('/')[-1].split('_')[0]\n",
    "    path = os.path.join('predictions_mel', f'{numbers}_predictions.txt')\n",
    "    if os.path.exists(path):\n",
    "        count += 1\n",
    "        continue\n",
    "    print(f'{count} of 39 files done')\n",
    "    with capture_output() as captured:\n",
    "        vae.predict(file, folder='predictions_mel')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## check for any empty predictions file\n",
    "(debugging)"
   ],
   "id": "2e2f258d7a45b484"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1998cbc3-f7e0-4602-a0c3-ab81de2b64bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 441.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for file in tqdm([f for f in os.listdir('predictions_mel') if f.endswith('.txt')]):\n",
    "    things = pd.read_csv(os.path.join('predictions_mel', file), sep='\\t')\n",
    "    if len(things) == 0:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41cddcb-9838-4692-9d55-07e0dd0aa8f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get metrics for the predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5136e5a9-fed5-4f57-8b94-24924e31f261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run postprocessing_original.ipynb\n",
    "%run ahc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9482c945-d24a-45d9-958a-d49c493c5525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_floats(text):\n",
    "    # Matches a floating-point number not surrounded by any non-whitespace characters\n",
    "    pattern = r'[\\d.]+'\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "\n",
    "def metrics_bc(predictions_file, boxCombo=False, threshold=0.5, outPath='metrics.csv', method=\"intersection\"):\n",
    "    \"\"\"\n",
    "    Gets binary classification metrics for a specified predictions file\n",
    "    :param predictions_file: path to predictions file\n",
    "    :param boxCombo: whether to use box combo\n",
    "    :param threshold: distance threshold for box combination agglomerative clustering\n",
    "    :param outPath: path of output file\n",
    "    :param method: method to implement box combinations (if box combination is desired)\n",
    "    :return: pandas dataframe containing binary classification metrics\n",
    "    \"\"\"\n",
    "    # Extract the prefix from the predictions file\n",
    "    prefix = find_floats(predictions_file)\n",
    "    ground = os.path.join('files', f'{prefix}-SS.txt')\n",
    "    ground = read_boxes(ground, False)\n",
    "    output = read_boxes(predictions_file, True)\n",
    "\n",
    "    if boxCombo:\n",
    "        # Import the box_combo function from ahc.ipynb\n",
    "        %run ahc.ipynb\n",
    "        output = box_combo(predictions_file, method, threshold)\n",
    "\n",
    "    fOut = nms(output, None)\n",
    "    things = getBoxSuccess(\n",
    "        predicted = fOut,\n",
    "        annotated = ground,\n",
    "        thresh = threshold,\n",
    "        compare = \"ovr\"\n",
    "    )\n",
    "    df = pd.DataFrame([things])\n",
    "    df['file'] = prefix\n",
    "    df.set_index('file', inplace=True)\n",
    "    df.to_csv(outPath)\n",
    "    return df\n",
    "\n",
    "def box_combo(file_path, method, threshold=0.5):\n",
    "    \"\"\"\n",
    "    This function reads in a file containing boxes and clusters them using Agglomerative Clustering.\n",
    "    :param file_path: predictions file path containing bounding boxes\n",
    "    :param method: overlap or intersection \n",
    "    :param threshold: Agglomerative Clustering distance threshold\n",
    "    :return: dataframe containing combined boxes\n",
    "    \"\"\"\n",
    "    # SEE AHC.IPYNB FOR MORE INFORMATION\n",
    "    \n",
    "    data = pd.read_csv(file_path, delimiter='\\t')\n",
    "    X = data[['Begin Time (s)', 'End Time (s)', 'Low Freq (Hz)', 'High Freq (Hz)']]\n",
    "    clusters = AgglomerativeClustering(n_clusters=None, distance_threshold=threshold).fit(X)\n",
    "\n",
    "    cluster_lst = []\n",
    "    for c in range(max(clusters.labels_) + 1):\n",
    "        indices = list(np.where(clusters.labels_ == c)[0])\n",
    "        df = X.iloc[indices]\n",
    "        #print(f'Cluster {c}:')\n",
    "        #print(df)\n",
    "        #print('\\n')\n",
    "\n",
    "        cluster = Cluster(boxes=df.transpose().values.tolist())\n",
    "        cluster_lst.append(cluster)\n",
    "    \n",
    "    combined = pd.DataFrame(columns=['Begin Time (s)', 'End Time (s)', 'Low Freq (Hz)', 'High Freq (Hz)'])\n",
    "    for c in cluster_lst:\n",
    "        if method == \"union\":\n",
    "            box = [min(c.boxes[0]), max(c.boxes[1]), min(c.boxes[2]), max(c.boxes[3])]\n",
    "        if method == \"intersection\":\n",
    "            box = [max(c.boxes[0]), min(c.boxes[1]), max(c.boxes[2]), min(c.boxes[3])]\n",
    "        combined.loc[len(combined)] = box\n",
    "    if not os.path.exists('combos_mel'):\n",
    "        os.makedirs('combos_mel')\n",
    "    combined.to_csv(f'combos_mel/{file_path.split(\"/\")[-1].split(\"_\")[0]}_{method}_box_combo_{method}.txt', sep='\\t', index=False)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78067c51-eb49-497c-bcbd-fa28b9db5cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = [os.path.join('predictions_mel', f) for f in os.listdir('predictions_mel') if f.endswith('_predictions.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d65322-c25b-405a-89e1-4789e4c8f6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 223.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    path = os.path.join('predictions_mel', file)\n",
    "    t = pd.read_csv(path, sep='\\t')\n",
    "    t['conf'] = 1.0\n",
    "    t.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb030b6-6977-4d45-aca6-9bd6c42218fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 121528.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    path = os.path.join('predictions_mel', file)\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    box_combo(path, 'intersection', 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b56dd9b8-faf9-4261-ac93-be318d0c68f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 129.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def fix(file_path):\n",
    "    # Create a temporary file\n",
    "    temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8')\n",
    "    \n",
    "    # Read the original file, remove outer quotes, and write to the temporary file\n",
    "    with open(file_path, 'r', encoding='utf-8') as infile, temp_file:\n",
    "        for line in infile:\n",
    "            # Strip quotes at the start and end of the line if they exist\n",
    "            cleaned_line = line.strip().strip('\\\"')\n",
    "            temp_file.write(cleaned_line + '\\n')\n",
    "    \n",
    "    # Close the temporary file to ensure all data is written\n",
    "    temp_file.close()\n",
    "    \n",
    "    # Load the cleaned data from the temporary file, specifying tab as the separator\n",
    "    df = pd.read_csv(temp_file.name, sep='\\t')\n",
    "    \n",
    "    # Write the DataFrame back to the original file using tab as the separator and ensuring no index is written\n",
    "    df.to_csv(file_path, sep='\\t', index=False)\n",
    "    \n",
    "    # Remove the temporary file\n",
    "    os.unlink(temp_file.name)\n",
    "\n",
    "# Example usage, assuming you have a list of files\n",
    "files = [os.path.join('predictions_mel', f) for f in os.listdir('predictions_mel') if f.endswith('_predictions.txt')]\n",
    "for file in tqdm(files):\n",
    "    fix(file)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get metrics",
   "id": "e0a87fd43de64cf7"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "424db20c-f54e-45ff-a5f9-4bab3c7f50b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 107.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numPredicted</th>\n",
       "      <th>numAnnotated</th>\n",
       "      <th>truePositives</th>\n",
       "      <th>falsePositives</th>\n",
       "      <th>falseNegatives</th>\n",
       "      <th>binaryAccuracy</th>\n",
       "      <th>binaryPrecision</th>\n",
       "      <th>BinaryRecall</th>\n",
       "      <th>binaryF1</th>\n",
       "      <th>nonbinaryAccuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6805.230202120825</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230203110826</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205210826</th>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230203090826</th>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230202000825</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206163827</th>\n",
       "      <td>426</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>372</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.040387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230202150825</th>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230203180826</th>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206090827</th>\n",
       "      <td>198</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>167</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230203150826</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230207120827</th>\n",
       "      <td>303</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>287</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230203210826</th>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205090826</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230202030825</th>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230207043827</th>\n",
       "      <td>426</td>\n",
       "      <td>267</td>\n",
       "      <td>7</td>\n",
       "      <td>411</td>\n",
       "      <td>260</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.020438</td>\n",
       "      <td>0.120375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230204030826</th>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230201090825</th>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230207000827</th>\n",
       "      <td>91</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205180826</th>\n",
       "      <td>32</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230204090826</th>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205150826</th>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230204003826</th>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230204120826</th>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205183826</th>\n",
       "      <td>141</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230203000825</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206233827</th>\n",
       "      <td>113</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206000826</th>\n",
       "      <td>110</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>68</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.084097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230204180826</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230201150825</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230204210826</th>\n",
       "      <td>105</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230202100825</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230201180825</th>\n",
       "      <td>59</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206210827</th>\n",
       "      <td>179</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230202180825</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206030826</th>\n",
       "      <td>341</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>335</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.025869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205000826</th>\n",
       "      <td>168</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230206100827</th>\n",
       "      <td>145</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230201210825</th>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.230205030826</th>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   numPredicted  numAnnotated  truePositives  falsePositives  \\\n",
       "file                                                                           \n",
       "6805.230202120825            21             6              0              21   \n",
       "6805.230203110826             9            10              0               9   \n",
       "6805.230205210826            46            79              0              46   \n",
       "6805.230203090826            58            15              0              58   \n",
       "6805.230202000825            34             1              0              34   \n",
       "6805.230206163827           426           374              2             424   \n",
       "6805.230202150825            29            12              0              29   \n",
       "6805.230203180826            70            44              0              70   \n",
       "6805.230206090827           198           168              1             194   \n",
       "6805.230203150826            28            13              0              28   \n",
       "6805.230207120827           303           288              1             302   \n",
       "6805.230203210826            74            51              0              74   \n",
       "6805.230205090826             7             2              0               7   \n",
       "6805.230202030825            35            14              0              35   \n",
       "6805.230207043827           426           267              7             411   \n",
       "6805.230204030826            56            16              0              56   \n",
       "6805.230201090825            95            50              0              95   \n",
       "6805.230207000827            91            32              0              91   \n",
       "6805.230205180826            32            67              0              32   \n",
       "6805.230204090826            28            15              0              28   \n",
       "6805.230205150826            30            24              0              30   \n",
       "6805.230204003826            88            77              0              88   \n",
       "6805.230204120826            92            70              0              92   \n",
       "6805.230205183826           141           100              0             141   \n",
       "6805.230203000825            27            12              0              27   \n",
       "6805.230206233827           113            48              0             113   \n",
       "6805.230206000826           110            69              1             109   \n",
       "6805.230204180826            17             3              0              17   \n",
       "6805.230201150825            30            12              0              30   \n",
       "6805.230204210826           105            72              0             105   \n",
       "6805.230202100825            29             3              0              29   \n",
       "6805.230201180825            59            37              0              59   \n",
       "6805.230206210827           179           116              0             179   \n",
       "6805.230202180825            20             4              0              20   \n",
       "6805.230206030826           341           336              1             340   \n",
       "6805.230205000826           168            92              0             168   \n",
       "6805.230206100827           145           113              0             145   \n",
       "6805.230201210825            44            16              0              44   \n",
       "6805.230205030826            29            21              0              29   \n",
       "\n",
       "                   falseNegatives  binaryAccuracy  binaryPrecision  \\\n",
       "file                                                                 \n",
       "6805.230202120825               6        0.000000         0.000000   \n",
       "6805.230203110826              10        0.000000         0.000000   \n",
       "6805.230205210826              79        0.000000         0.000000   \n",
       "6805.230203090826              15        0.000000         0.000000   \n",
       "6805.230202000825               1        0.000000         0.000000   \n",
       "6805.230206163827             372        0.004695         0.004695   \n",
       "6805.230202150825              12        0.000000         0.000000   \n",
       "6805.230203180826              44        0.000000         0.000000   \n",
       "6805.230206090827             167        0.005051         0.005128   \n",
       "6805.230203150826              13        0.000000         0.000000   \n",
       "6805.230207120827             287        0.003300         0.003300   \n",
       "6805.230203210826              51        0.000000         0.000000   \n",
       "6805.230205090826               2        0.000000         0.000000   \n",
       "6805.230202030825              14        0.000000         0.000000   \n",
       "6805.230207043827             260        0.016432         0.016746   \n",
       "6805.230204030826              16        0.000000         0.000000   \n",
       "6805.230201090825              50        0.000000         0.000000   \n",
       "6805.230207000827              32        0.000000         0.000000   \n",
       "6805.230205180826              67        0.000000         0.000000   \n",
       "6805.230204090826              15        0.000000         0.000000   \n",
       "6805.230205150826              24        0.000000         0.000000   \n",
       "6805.230204003826              77        0.000000         0.000000   \n",
       "6805.230204120826              70        0.000000         0.000000   \n",
       "6805.230205183826             100        0.000000         0.000000   \n",
       "6805.230203000825              12        0.000000         0.000000   \n",
       "6805.230206233827              48        0.000000         0.000000   \n",
       "6805.230206000826              68        0.009091         0.009091   \n",
       "6805.230204180826               3        0.000000         0.000000   \n",
       "6805.230201150825              12        0.000000         0.000000   \n",
       "6805.230204210826              72        0.000000         0.000000   \n",
       "6805.230202100825               3        0.000000         0.000000   \n",
       "6805.230201180825              37        0.000000         0.000000   \n",
       "6805.230206210827             116        0.000000         0.000000   \n",
       "6805.230202180825               4        0.000000         0.000000   \n",
       "6805.230206030826             335        0.002933         0.002933   \n",
       "6805.230205000826              92        0.000000         0.000000   \n",
       "6805.230206100827             113        0.000000         0.000000   \n",
       "6805.230201210825              16        0.000000         0.000000   \n",
       "6805.230205030826              21        0.000000         0.000000   \n",
       "\n",
       "                   BinaryRecall  binaryF1  nonbinaryAccuracy  \n",
       "file                                                          \n",
       "6805.230202120825      0.000000  0.000000           0.000000  \n",
       "6805.230203110826      0.000000  0.000000           0.000000  \n",
       "6805.230205210826      0.000000  0.000000           0.000000  \n",
       "6805.230203090826      0.000000  0.000000           0.000000  \n",
       "6805.230202000825      0.000000  0.000000           0.000000  \n",
       "6805.230206163827      0.005348  0.005000           0.040387  \n",
       "6805.230202150825      0.000000  0.000000           0.000000  \n",
       "6805.230203180826      0.000000  0.000000           0.000000  \n",
       "6805.230206090827      0.005952  0.005510           0.266667  \n",
       "6805.230203150826      0.000000  0.000000           0.000000  \n",
       "6805.230207120827      0.003472  0.003384           0.035264  \n",
       "6805.230203210826      0.000000  0.000000           0.000000  \n",
       "6805.230205090826      0.000000  0.000000           0.000000  \n",
       "6805.230202030825      0.000000  0.000000           0.000000  \n",
       "6805.230207043827      0.026217  0.020438           0.120375  \n",
       "6805.230204030826      0.000000  0.000000           0.000000  \n",
       "6805.230201090825      0.000000  0.000000           0.000000  \n",
       "6805.230207000827      0.000000  0.000000           0.000000  \n",
       "6805.230205180826      0.000000  0.000000           0.000000  \n",
       "6805.230204090826      0.000000  0.000000           0.000000  \n",
       "6805.230205150826      0.000000  0.000000           0.000000  \n",
       "6805.230204003826      0.000000  0.000000           0.000000  \n",
       "6805.230204120826      0.000000  0.000000           0.000000  \n",
       "6805.230205183826      0.000000  0.000000           0.000000  \n",
       "6805.230203000825      0.000000  0.000000           0.000000  \n",
       "6805.230206233827      0.000000  0.000000           0.000000  \n",
       "6805.230206000826      0.014493  0.011173           0.084097  \n",
       "6805.230204180826      0.000000  0.000000           0.000000  \n",
       "6805.230201150825      0.000000  0.000000           0.000000  \n",
       "6805.230204210826      0.000000  0.000000           0.000000  \n",
       "6805.230202100825      0.000000  0.000000           0.000000  \n",
       "6805.230201180825      0.000000  0.000000           0.000000  \n",
       "6805.230206210827      0.000000  0.000000           0.000000  \n",
       "6805.230202180825      0.000000  0.000000           0.000000  \n",
       "6805.230206030826      0.002976  0.002954           0.025869  \n",
       "6805.230205000826      0.000000  0.000000           0.000000  \n",
       "6805.230206100827      0.000000  0.000000           0.000000  \n",
       "6805.230201210825      0.000000  0.000000           0.000000  \n",
       "6805.230205030826      0.000000  0.000000           0.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything = pd.DataFrame()\n",
    "folder = 'combos_mel'\n",
    "files = [f for f in os.listdir(folder) if f.endswith('box_combo_intersection.txt')]\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(f'{folder}/{file}', sep='\\t')\n",
    "    df['Species confidence'] = 1.0\n",
    "    df.to_csv(f'{folder}/{file}', sep='\\t', index=False)\n",
    "    stuff = metrics_bc(f'{folder}/{file}', boxCombo=False)\n",
    "    everything = pd.concat([everything, stuff])\n",
    "everything.to_csv('metrics_MEL.csv')\n",
    "everything"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary of metrics",
   "id": "f66763bb3536ad83"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "224c971e-f40f-4554-bcdc-480b6c2d60cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>39.0</td>\n",
       "      <td>6805.2302</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6805.2302</td>\n",
       "      <td>6805.2302</td>\n",
       "      <td>6805.2302</td>\n",
       "      <td>6805.2302</td>\n",
       "      <td>6805.2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numPredicted</th>\n",
       "      <td>39.0</td>\n",
       "      <td>98.2821</td>\n",
       "      <td>107.5815</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>111.5000</td>\n",
       "      <td>426.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numAnnotated</th>\n",
       "      <td>39.0</td>\n",
       "      <td>70.4872</td>\n",
       "      <td>93.5186</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>374.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truePositives</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1.1773</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>falsePositives</th>\n",
       "      <td>39.0</td>\n",
       "      <td>97.6667</td>\n",
       "      <td>106.0261</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>58.0000</td>\n",
       "      <td>111.0000</td>\n",
       "      <td>424.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>falseNegatives</th>\n",
       "      <td>39.0</td>\n",
       "      <td>70.1538</td>\n",
       "      <td>92.8024</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>372.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryAccuracy</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryPrecision</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BinaryRecall</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binaryF1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonbinaryAccuracy</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count       mean       std        min        25%  \\\n",
       "file                39.0  6805.2302    0.0000  6805.2302  6805.2302   \n",
       "numPredicted        39.0    98.2821  107.5815     7.0000    29.0000   \n",
       "numAnnotated        39.0    70.4872   93.5186     1.0000    12.5000   \n",
       "truePositives       39.0     0.3333    1.1773     0.0000     0.0000   \n",
       "falsePositives      39.0    97.6667  106.0261     7.0000    29.0000   \n",
       "falseNegatives      39.0    70.1538   92.8024     1.0000    12.5000   \n",
       "binaryAccuracy      39.0     0.0011    0.0031     0.0000     0.0000   \n",
       "binaryPrecision     39.0     0.0011    0.0032     0.0000     0.0000   \n",
       "BinaryRecall        39.0     0.0015    0.0049     0.0000     0.0000   \n",
       "binaryF1            39.0     0.0012    0.0038     0.0000     0.0000   \n",
       "nonbinaryAccuracy   39.0     0.0147    0.0481     0.0000     0.0000   \n",
       "\n",
       "                         50%        75%        max  \n",
       "file               6805.2302  6805.2302  6805.2302  \n",
       "numPredicted         58.0000   111.5000   426.0000  \n",
       "numAnnotated         37.0000    78.0000   374.0000  \n",
       "truePositives         0.0000     0.0000     7.0000  \n",
       "falsePositives       58.0000   111.0000   424.0000  \n",
       "falseNegatives       37.0000    78.0000   372.0000  \n",
       "binaryAccuracy        0.0000     0.0000     0.0164  \n",
       "binaryPrecision       0.0000     0.0000     0.0167  \n",
       "BinaryRecall          0.0000     0.0000     0.0262  \n",
       "binaryF1              0.0000     0.0000     0.0204  \n",
       "nonbinaryAccuracy     0.0000     0.0000     0.2667  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_mel = pd.read_csv('metrics_MEL.csv')\n",
    "metrics_mel.describe().round(4).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
