{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25446d0",
   "metadata": {},
   "source": [
    "# Here is where anyone can input a decimated WAV file and receieve a TXT file that contains bounding box locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f7f23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T22:47:07.213520Z",
     "start_time": "2024-02-28T22:47:07.196657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'# Only run once\\n!pip install import_ipynb\\n!pip install opencv-python\\n!pip install librosa\\n!pip install tensorflow\\n!pip install tensorflow_probability\\n!pip install tensorflow_addons\\n!pip install scikit-maad'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Only run once\n",
    "!pip install import_ipynb\n",
    "!pip install opencv-python\n",
    "!pip install librosa\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_probability\n",
    "!pip install tensorflow_addons\n",
    "!pip install scikit-maad\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fbd37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T22:47:44.716865Z",
     "start_time": "2024-02-28T22:47:32.912717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 14:47:37.197030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('/Users/sucheen/anaconda3/lib/python3.11/site-packages')\n",
    "import import_ipynb\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from awsKeys import awsKeys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "KEYS = \"../../ssundar_accessKeys.csv\"\n",
    "aws_access_key_id, aws_secret_access_key = awsKeys(KEYS)\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-east-1'  # or your preferred region\n",
    ")\n",
    "s3 = session.resource('s3')\n",
    "\n",
    "# S3 Bucket for Professor's Account is 'monitoring-whale-recordings'\n",
    "# S3 Bucket for our free tier Account is 'monitoring-whale-records'\n",
    "bucket_name = 'whale-recordings'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Remove the previous _finalPreds.txt file if it was not erased yet\n",
    "os.system(f'rm -rf *_finalPreds.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6050d408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T22:47:44.718364Z",
     "start_time": "2024-02-28T22:47:44.710805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Welcome message\n",
    "# User input (decimated WAV file)\n",
    "#wfile = input(\"Enter decimated WAV file (i.e., ###.#####_processed.wav): \")\n",
    "#wfile = '671658014.180929033558_processed.wav'\n",
    "wfile = '6805.230201070825_processed.wav'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Run this cell and not the below ones\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "# Create an S3 client with the AWS key and secret\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "%run preprocessing.ipynb\n",
    "\n",
    "# Assuming 'WAV_FILES' is a list of tuples with (file_name, key_in_bucket)\n",
    "for wf in WAV_FILES:\n",
    "    if wfile == wf[0]:\n",
    "        s3_client.download_file(bucket_name, wf[1], f'{wfile}')\n",
    "        print(wfile in os.listdir())\n",
    "    \n",
    "\n",
    "# Note: You would only download the file after the restoration is complete.\n",
    "# Since the restoration can take hours, you might not be able to download immediately after initiating the restore.\n",
    "# You would need to check the object's restoration status before attempting to download.\n",
    "\n",
    "wfile_pcen, sr = process_wav(wfile, running=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64d20e3ec7e60cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"# Implement PCEN\n",
    "# DON'T RUN THIS\n",
    "\n",
    "# Need preprocessing functions\n",
    "%run preprocessing.ipynb\n",
    "\n",
    "for wf in WAV_FILES:\n",
    "    print(wf[0])\n",
    "    if wfile == wf[0]:\n",
    "        # Download WAV file from S3 Bucket\n",
    "        restore_request = {\n",
    "            'Days': 365,\n",
    "            'GlacierJobParameters': {\n",
    "                'Tier': 'Standard'\n",
    "            },\n",
    "        }\n",
    "        s3.restore_object(Bucket=bucket_name, Key=wf[0], RestoreRequest=restore_request)\n",
    "        s3.meta.client.download_file(bucket_name, wf[1], wf[0])\n",
    "\n",
    "wfile_pcen, sr = process_wav(wfile, running=True)\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a890d8b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30577d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and get initial boxes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Need model functions\n",
    "%run model.ipynb\n",
    "\n",
    "vae = keras.models.load_model(\"test_vae_mod_pcen\", custom_objects={\"vae_loss_function\": vae_loss_function})\n",
    "non_normal_scores = error_dataset(vae, wfile_pcen, False, sr=sr)\n",
    "bounding_boxes = run_model(non_normal_scores)\n",
    "titles = [\"Begin Time (s)\", \"End Time (s)\", \"Low Freq (Hz)\", \"High Freq (Hz)\", \"Species confidence\"]\n",
    "wfile_preds = wfile.split('_')[0] + \"_predictions.txt\"\n",
    "write_array_to_file(bounding_boxes, titles, wfile_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize boxes from model\n",
    "\n",
    "# Need postprocessing functions\n",
    "%run postprocessing.ipynb\n",
    "wfile_preds = wfile.split('_')[0] + \"_predictions.txt\"\n",
    "output = read_boxes(wfile_preds, True)\n",
    "\n",
    "fOut = nms(\n",
    "    filterBoxes(\n",
    "        filterBoxes(\n",
    "            filterBoxes(\n",
    "                output,\n",
    "                dim = 'top',\n",
    "                upper = False,\n",
    "                thresh = 2400\n",
    "            ), \n",
    "            thresh = 0.3\n",
    "        ),\n",
    "        dim = 'dur',\n",
    "        thresh = 0.25\n",
    "        \n",
    "    ), \n",
    "    0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert output into TXT file\n",
    "\n",
    "df = pd.DataFrame.from_dict(fOut, orient='index')\n",
    "wfile_nums = wfile.split('_')[0]\n",
    "np.savetxt(wfile_nums + \"_finalPreds.txt\", df.sort_index(), fmt='%s',\n",
    "           delimiter='\\t', header=', '.join(map(str,titles)))\n",
    "print(f'{wfile_nums}_finalPreds.txt has been created.')\n",
    "\n",
    "# Remove the _predictions.txt and _processed.wav (no longer needed)\n",
    "os.system(f'rm -rf {wfile_nums}_predictions.txt {wfile_nums}_processed.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8b36be2eac1bceb8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run these cells"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9f7a884bee6c185"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sucheen/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preprocessing\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('6805.230201090825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230201090825-SS.txt'),\n ('6805.230201150825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230201150825-SS.txt'),\n ('6805.230201180825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230201180825-SS.txt'),\n ('6805.230201210825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230201210825-SS.txt'),\n ('6805.230202000825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230202000825-SS.txt'),\n ('6805.230202030825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230202030825-SS.txt'),\n ('6805.230202100825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230202100825-SS.txt'),\n ('6805.230202120825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230202120825-SS.txt'),\n ('6805.230202150825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230202150825-SS.txt'),\n ('6805.230202180825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230202180825-SS.txt'),\n ('6805.230203000825-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230203000825-SS.txt'),\n ('6805.230203090826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230203090826-SS.txt'),\n ('6805.230203110826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230203110826-SS.txt'),\n ('6805.230203150826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230203150826-SS.txt'),\n ('6805.230203180826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230203180826-SS.txt'),\n ('6805.230203210826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230203210826-SS.txt'),\n ('6805.230204003826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230204003826-SS.txt'),\n ('6805.230204030826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230204030826-SS.txt'),\n ('6805.230204090826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230204090826-SS.txt'),\n ('6805.230204120826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230204120826-SS.txt'),\n ('6805.230204180826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230204180826-SS.txt'),\n ('6805.230204210826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230204210826-SS.txt'),\n ('6805.230205000826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205000826-SS.txt'),\n ('6805.230205030826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205030826-SS.txt'),\n ('6805.230205090826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205090826-SS.txt'),\n ('6805.230205150826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205150826-SS.txt'),\n ('6805.230205180826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205180826-SS.txt'),\n ('6805.230205183826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205183826-SS.txt'),\n ('6805.230205183826.AW.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205183826.AW.txt'),\n ('6805.230205210826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230205210826-SS.txt'),\n ('6805.230206000826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206000826-SS.txt'),\n ('6805.230206030826-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206030826-SS.txt'),\n ('6805.230206090827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206090827-SS.txt'),\n ('6805.230206100827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206100827-SS.txt'),\n ('6805.230206163827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206163827-SS.txt'),\n ('6805.230206210827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206210827-SS.txt'),\n ('6805.230206233827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230206233827-SS.txt'),\n ('6805.230207000827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230207000827-SS.txt'),\n ('6805.230207043827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230207043827-SS.txt'),\n ('6805.230207120827-SS.txt',\n  'CPhydrophone/Avila/Deployment 2/selection-tables/6805.230207120827-SS.txt')]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of files to be processed\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('/Users/sucheen/anaconda3/lib/python3.11/site-packages')\n",
    "import import_ipynb\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from awsKeys import awsKeys\n",
    "from tensorflow.keras import layers,Input\n",
    "from tensorflow.keras.layers import Dense,Lambda\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from PIL import ImageColor,ImageFont\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import pdb\n",
    "import glob\n",
    "import cv2\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow_addons as tfa\n",
    "import boto3\n",
    "\n",
    "KEYS = \"../../ssundar_accessKeys.csv\"\n",
    "aws_access_key_id, aws_secret_access_key = awsKeys(KEYS)\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "\n",
    "%run model_functions.ipynb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# List to store processed data\n",
    "processed_data = []\n",
    "D2 = []\n",
    "backgroundFiles = []\n",
    "for wf in WAV_FILES:\n",
    "    if \"Deployment 2\" in wf[1]:\n",
    "        D2.append(wf)\n",
    "\n",
    "path = \"CPhydrophone/Avila/Deployment 2/selection-tables/\"\n",
    "\n",
    "keys = [obj.key for obj in bucket.objects.all()]\n",
    "selectionTables = [(obj.split(\"/\")[-1], obj) for obj in keys if path in obj][1:]\n",
    "selectionTables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T22:48:22.172163Z",
     "start_time": "2024-02-28T22:48:00.873985Z"
    }
   },
   "id": "f8918b3d9268761c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selectionTables)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T22:48:52.026446Z",
     "start_time": "2024-02-28T22:48:51.987451Z"
    }
   },
   "id": "237f6956cdebcd98",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [04:20<01:07,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 6805.230205183826.AW.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [05:34<00:00,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 39 of 40 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "wavPath = \"CPhydrophone/Avila/Deployment 2/wav-files/decimated_files/\"\n",
    "backgroundFiles = []\n",
    "for item in tqdm(selectionTables):\n",
    "    try:\n",
    "        ss = item[0]\n",
    "        wav = ss.split(\"-SS.txt\")[0] + \"_processed.wav\"\n",
    "        # create a background noise file\n",
    "        s3_client.download_file(bucket_name, item[1], ss)\n",
    "        s3_client.download_file(bucket_name, wavPath + wav, wav)\n",
    "        background_noise = exclude(wav, labels_file=ss)[1]\n",
    "        backgroundFiles.append(background_noise)\n",
    "        # remove the two files\n",
    "    except:\n",
    "        print(f\"Error with {item[0]}\")\n",
    "        continue\n",
    "# remove all .wav and files that end in -ss.txt\n",
    "print(f'Got {len(backgroundFiles)} of {len(selectionTables)} files')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T22:54:29.159725Z",
     "start_time": "2024-02-28T22:48:54.244024Z"
    }
   },
   "id": "3569b4529182960d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#backgroundFiles = [b[1] for b in backgroundFiles]\n",
    "backgroundFiles = [pad_sequences(backgroundFiles, padding='post', dtype='float32') for b in backgroundFiles]\n",
    "cat_background_noise = np.concatenate(backgroundFiles, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-28T23:00:32.500448Z"
    }
   },
   "id": "df29aca327347a1e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# concatenate all the background noise files into a single dataset\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m cat_background_noise \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbackgroundFiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# write D2 to a file\u001B[39;00m\n\u001B[1;32m      5\u001B[0m np\u001B[38;5;241m.\u001B[39msavetxt(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mD2.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, D2, fmt\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m, delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mstr\u001B[39m,[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile Name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey\u001B[39m\u001B[38;5;124m\"\u001B[39m])))\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# concatenate all the background noise files into a single dataset\n",
    "cat_background_noise = np.concatenate(backgroundFiles, axis=0)\n",
    "    \n",
    "# write D2 to a file\n",
    "np.savetxt(\"D2.txt\", D2, fmt='%s', delimiter='\\t', header=', '.join(map(str,[\"File Name\", \"Key\"])))\n",
    "\n",
    "print(\"Out of Here\\nTraining Time\")\n",
    "\n",
    "background_noise = \"avila_filtered.wav\"\n",
    "predicting_file = \"6805.230201070825_processed.wav\"\n",
    "print(predicting_file)\n",
    "\n",
    "# Get predicting file\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "bucket_name = 'whale-recordings'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "for wf in WAV_FILES:\n",
    "    if predicting_file == wf[0]:\n",
    "        print(wf[1])\n",
    "        print(predicting_file)\n",
    "        # Download WAV file from S3 Bucket\n",
    "        s3_client.download_file(bucket_name, wf[1], wf[0])\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"training\")\n",
    "dataset_train,sr = process_wav(cat_background_noise, running = True)\n",
    "print(\"testing\")\n",
    "dataset_test,sr = process_wav(predicting_file, running = True)\n",
    "print(\"finshed\")\n",
    "\n",
    "\n",
    "train_model(combined_data,True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T22:54:36.977293Z",
     "start_time": "2024-02-28T22:54:34.726426Z"
    }
   },
   "id": "8342a4b18078b34a",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
