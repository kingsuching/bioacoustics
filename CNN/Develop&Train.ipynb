{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d36696",
   "metadata": {},
   "source": [
    "# This notebook includes code to build, tune, and train models using SageMaker's object detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037282c",
   "metadata": {},
   "source": [
    "Using a notebook as opposed to SageMaker's UI gives us the advantage of having access to all of the model artifacts in one place. It also allows us to specify all input data and output locations in a single notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6742a5",
   "metadata": {},
   "source": [
    "#### Code and documentation in this notebook was heavily inspired by the following Object Detection sample notebook created by Amazon SageMaker:\n",
    "https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/object_detection_birds/object_detection_birds.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2d24e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1e0d7",
   "metadata": {},
   "source": [
    "#### First, specify if you want to train a model off of a REC file (i.e., a RecordIO File) or an Augmented Manifest File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify either \"REC\" or \"AugmentedManifest\"\n",
    "data_file = \"REC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d7233",
   "metadata": {},
   "source": [
    "This initializes important specifications with different values depending on the which data file is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2766185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the professor's S3 Bucket dedicated to machine learning\n",
    "    # Note that part of the name has been redacted for privacy purposes\n",
    "bucket_name = \"sagemaker-us-west-2-************\"\n",
    "\n",
    "# If training off of a REC File:\n",
    "if data_file == \"REC\":\n",
    "    print(\"Training off of RecordIO File\")\n",
    "    train_path = f\"s3://{bucket_name}/train/train_full.rec\"\n",
    "    val_path = f\"s3://{bucket_name}/validation/val.rec\"\n",
    "    input_mode = \"File\"\n",
    "    content_type=\"application/x-recordio\"\n",
    "    s3_data_type = \"S3Prefix\"\n",
    "    attribute_names = None\n",
    "\n",
    "# If training off of an Augmented Manifest File:\n",
    "elif data_file == \"AugmentedManifest\":\n",
    "    print(\"Training off of Augmented Manifest File\")\n",
    "    train_path = f\"s3://{bucket_name}/train_full_manifest/train_full_AugmentedManifestFile.jsonl\"\n",
    "    val_path = f\"s3://{bucket_name}/val_manifest/val_AugmentedManifestFile.jsonl\"\n",
    "    input_mode = \"Pipe\"\n",
    "    content_type=\"application/x-image\"\n",
    "    s3_data_type = \"ManifestFile\"\n",
    "    attribute_names = [\"spectrogram\", \"boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4dd74",
   "metadata": {},
   "source": [
    "#### Now we create a connection to the professor's S3 Bucket, a connection to the data files, and a connection to SageMaker's object detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d3371",
   "metadata": {},
   "source": [
    "We start by connecting to the S3 Bucket where we have all of our training data and validation data. We also need to specify their precise file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd80be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for the S3 Bucket\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Creating a connection to the S3 Bucket that has our training and validation data\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Indicating the exact location of training and validation data\n",
    "s3_train_data = train_path\n",
    "s3_validation_data = val_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003ed35",
   "metadata": {},
   "source": [
    "We need to provide proper authentication to allow for the use of Amazon's SageMaker services, so we must specify our execution role from an account with SageMaker access. This also allows for access to the data in the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets execution role to authenticate usage of SageMaker services and access to S3 bucket\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2431fb",
   "metadata": {},
   "source": [
    "We need to get the URI to the Amazon SageMaker Object Detection docker image. This ensures the estimator uses the correct algorithm from the correct region, which is specified based on the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04287b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Retrieves the URI to the object detection docker image\n",
    "training_image = image_uris.retrieve(\n",
    "    region=sess.boto_region_name, framework=\"object-detection\", version=\"latest\"\n",
    ")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d6f23",
   "metadata": {},
   "source": [
    "We must also specify our desired output location (folder path within the S3 bucket) for model artifacts once the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd763a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Bucket output location for model artifacts\n",
    "s3_output_location = f\"s3://{bucket_name}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4bc930",
   "metadata": {},
   "source": [
    "#### Now we can start building the model framework and specifying the parameter values for the model type. Some examples of these are the algorithm, execution role, instance type, and output location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ce75a",
   "metadata": {},
   "source": [
    "Here is a link documenting the Estimator object and its attributes: \n",
    "https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebe9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model framework using a SageMaker estimator object\n",
    "od_model = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    volume_size=5,\n",
    "    max_run=360000,\n",
    "    input_mode=input_mode,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2fef28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb937743",
   "metadata": {},
   "source": [
    "#### Now we define the hyperparameters for our object detection model. At the time of creating this notebook, SageMaker's object detection algorithm supports 2 base networks, the VGG-16 and ResNet-50. The base network only gets used if \"use_pretrained_model\" is equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb89f7c",
   "metadata": {},
   "source": [
    "Here is a link to the hyperparameter documentation for object detection models in SageMaker: https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-api-config.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set hyperparameters for the model\n",
    "def set_hyperparameters(num_classes, num_training_samples, mini_batch_size, num_epochs, learning_rate, lr_steps,\n",
    "                        lr_scheduler_factor, base_network=\"vgg-16\", use_pretrained_model = 0, optimizer=\"sgd\", \n",
    "                        momentum=0.9, weight_decay=0.0005, overlap_threshold=0.5, nms_threshold=0.45,\n",
    "                        image_shape=512, label_width=350):\n",
    "    num_classes = num_classes\n",
    "    num_training_samples = num_training_samples\n",
    "    print(\"num classes: {}, num training images: {}, mini batch size: {}, \\n num_epochs: {}, learning rate: {}, lr steps: {}, lr scheduler factor: {}, \\n base network: {}, optimizer: {}, momentum: {}, weight decay: {}, \\n overlap threshold: {}, nms threshold: {}\".format(\n",
    "        num_classes, num_training_samples,\n",
    "        mini_batch_size, num_epochs, learning_rate,\n",
    "        lr_steps, lr_scheduler_factor, base_network,\n",
    "        optimizer, momentum, weight_decay,\n",
    "        overlap_threshold, nms_threshold))\n",
    "\n",
    "    od_model.set_hyperparameters(\n",
    "        base_network=base_network,\n",
    "        use_pretrained_model=use_pretrained_model,\n",
    "        num_classes=num_classes,\n",
    "        mini_batch_size=mini_batch_size,\n",
    "        epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        lr_scheduler_step=lr_steps,\n",
    "        lr_scheduler_factor=lr_scheduler_factor,\n",
    "        optimizer=optimizer,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay,\n",
    "        early_stopping = True,\n",
    "        #early_stopping = False,\n",
    "        early_stopping_min_epochs = 70,\n",
    "        overlap_threshold=overlap_threshold,\n",
    "        nms_threshold=nms_threshold,\n",
    "        image_shape=image_shape,\n",
    "        label_width=label_width,\n",
    "        num_training_samples=num_training_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "set_hyperparameters(num_classes = 5, \n",
    "                    num_training_samples = 10400, \n",
    "                    mini_batch_size = 4, \n",
    "                    num_epochs = 100, \n",
    "                    learning_rate = 0.001, \n",
    "                    lr_steps = \"33,67\", \n",
    "                    lr_scheduler_factor = 0.1,\n",
    "                    use_pretrained_model = 1,\n",
    "                    optimizer = \"rmsprop\", \n",
    "                    momentum = 0.22092291710943074, \n",
    "                    weight_decay = 0.000024952493030102602)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4124064",
   "metadata": {},
   "source": [
    "### Now, different code chunks need to be run depending on whether your goal is to tune a model or train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a18a7",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53844b",
   "metadata": {},
   "source": [
    "Regardless of what kind of tuning job you create, run the following library import statements now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95604728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sagemaker import tuner\n",
    "from sagemaker import parameter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dd269",
   "metadata": {},
   "source": [
    "#### Now, different code chunks need to be run depending on whether your goal is to tune a model from scratch or tune a model based on a past tuning job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b572200",
   "metadata": {},
   "source": [
    "## Tuning a Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f496b",
   "metadata": {},
   "source": [
    "Template for Hyperparameter Tuning comes from the following sample notebook created by Amazon SageMaker: https://github.com/aws/amazon-sagemaker-examples/blob/main/hyperparameter_tuning/xgboost_random_log/hpo_xgboost_random_log.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a \"HyperparameterTuner\" object and specifies its parameters (see SageMaker documentation for more information)\n",
    "\n",
    "tuner_log = tuner.HyperparameterTuner(\n",
    "    estimator = od_model,\n",
    "    objective_metric_name = \"validation:mAP\",\n",
    "    hyperparameter_ranges = {\"learning_rate\": parameter.ContinuousParameter(min_value = 0.00155, max_value = 0.00156),\n",
    "                            #\"mini_batch_size\": parameter.IntegerParameter(min_value = 1, max_value = 5),\n",
    "                            \"momentum\": parameter.ContinuousParameter(min_value = 0.19494, max_value = 0.19495),\n",
    "                            #\"optimizer\": parameter.CategoricalParameter(values = ['rmsprop', 'adam', 'sgd', 'adadelta']),\n",
    "                            \"weight_decay\": parameter.ContinuousParameter(min_value = 0.0000173708, max_value = 0.0000173709)},\n",
    "    max_jobs=1,\n",
    "    max_parallel_jobs=1,\n",
    "    strategy=\"Bayesian\",\n",
    "    early_stopping_type = \"Auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96576612",
   "metadata": {},
   "source": [
    "Now we can submit the tuning job using the fit method. Once it is done, we can access model artifacts in the S3 bucket where the output directory was specified previously. Feel free to close this notebook and stop the notebook instance once the tuning job has begun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting the tuning job\n",
    "\"\"\"WARNING: Make sure you specify a unique, informative, and concise name for the training job.\"\"\"\n",
    "tuner_log.fit(\n",
    "    {\"train\": s3_train_data, \"validation\": s3_validation_data},\n",
    "    logs=True,\n",
    "    include_cls_metadata=False,\n",
    "    # Example of including information on the tuning job's start time within its name\n",
    "        # job_name=\"cpbio-1stTJ\" + time.strftime(\"%Y%m%d-%H-%M-%S\", time.gmtime()),\n",
    "    job_name = \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf8eb2",
   "metadata": {},
   "source": [
    "## Tuning a Model Based on Past Tuning Job(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819013f",
   "metadata": {},
   "source": [
    "The rest of the hyperparameter tuning code comes from the following sample notebook created by SageMaker: https://github.com/aws/amazon-sagemaker-examples/blob/main/hyperparameter_tuning/image_classification_warmstart/hpo_image_classification_warmstart.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c622a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements \"Warm Start\" (the means by which a new tuning job can obtain information from past tuning jobs)\n",
    "from sagemaker.tuner import WarmStartConfig, WarmStartTypes\n",
    "\n",
    "\"\"\"Specify the name(s) of the past tuning job(s) you want the new tuning job to inherit from. You can specify up to five.\"\"\"\n",
    "parent_tuning_jobs = {\"\", \"\"}\n",
    "warm_start_config = WarmStartConfig(\n",
    "    WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM, parents=parent_tuning_jobs\n",
    ")\n",
    "\n",
    "parent_tuning_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies hyperparameter ranges for the new tuning job, and passes in information for accessing past tuning jobs\n",
    "from sagemaker import tuner\n",
    "from sagemaker import parameter\n",
    "import time\n",
    "\n",
    "tuner_warm_start = tuner.HyperparameterTuner(\n",
    "    estimator = od_model,\n",
    "    objective_metric_name = \"validation:mAP\",\n",
    "    hyperparameter_ranges = {\"learning_rate\": parameter.ContinuousParameter(min_value = 0.0005, max_value = 0.0015),\n",
    "                            \"momentum\": parameter.ContinuousParameter(min_value = 0.21, max_value = 0.23),\n",
    "                            \"weight_decay\": parameter.ContinuousParameter(min_value = 0.000015, max_value = 0.000035)},\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=1,\n",
    "    strategy=\"Bayesian\",\n",
    "    early_stopping_type = \"Auto\",\n",
    "    warm_start_config=warm_start_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608bc24",
   "metadata": {},
   "source": [
    "Now we can submit the tuning job using the fit method. Once it is done, we can access model artifacts in the S3 bucket where the output directory was specified previously. Feel free to close this notebook and stop the notebook instance once the tuning job has begun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting the Tuning Job\n",
    "\"\"\"WARNING: Make sure you specify a unique, informative, and concise name for the tuning job.\"\"\"\n",
    "tuner_warm_start.fit(\n",
    "    {\"train\": s3_train_data, \"validation\": s3_validation_data},\n",
    "    logs=True,\n",
    "    include_cls_metadata=False,\n",
    "    job_name=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10fc25",
   "metadata": {},
   "source": [
    "## Visualizing Results from a Tuning Job (Wait Until Tuning Job is Complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abafda6e",
   "metadata": {},
   "source": [
    "#### Regardless of whether you tuned from scratch or used \"warm start\", the following code chunks help visualize the tuning job's results. Note that you can close this notebook and stop the notebook instance, and you will still be able to run this code to visualize results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac755f14",
   "metadata": {},
   "source": [
    "This code chunk displays a table summarizing the tuning job's information and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can bring up a table of metrics once the tuning job completes\n",
    "\n",
    "\"\"\"Specify the name of the tuning job you want to visualize results for.\"\"\"\n",
    "tuning_job_name = \"\"\n",
    "\n",
    "from sagemaker import analytics\n",
    "\n",
    "tuner_parent_metrics = analytics.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "if not tuner_parent_metrics.dataframe().empty:\n",
    "    df_parent = tuner_parent_metrics.dataframe().sort_values(\n",
    "        [\"FinalObjectiveValue\"], ascending=False\n",
    "    )\n",
    "\n",
    "df_parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce117de1",
   "metadata": {},
   "source": [
    "This code chunk plots the mAP scores for all training jobs within the tuning job. This assumes you have run the previous code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29963c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots how \"mean average precision\" changes as tuning progresses\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_parent_objective_value = df_parent[df_parent[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "\n",
    "p = figure(\n",
    "    plot_width=900,\n",
    "    plot_height=400,\n",
    "    x_axis_type=\"datetime\",\n",
    "    x_axis_label=\"datetime\",\n",
    "    y_axis_label=\"validation:mAP\",\n",
    ")\n",
    "p.circle(\n",
    "    source=df_parent_objective_value, x=\"TrainingStartTime\", y=\"FinalObjectiveValue\", color=\"black\"\n",
    ")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87d0df",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc7370",
   "metadata": {},
   "source": [
    "#### Now we can submit the training job using the fit method. Once it is done, we can access model artifacts in the S3 bucket where the output directory was specified previously. Feel free to close this notebook and stop the notebook instance once the training job has begun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5785a3",
   "metadata": {},
   "source": [
    "Before we submit a training job, we must specify our data types and the locations for the data channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying training and validation inputs\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=content_type,\n",
    "    s3_data_type=s3_data_type,\n",
    "    attribute_names = attribute_names\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=content_type,\n",
    "    s3_data_type=s3_data_type,\n",
    "    attribute_names = attribute_names\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbb881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Submitting the training job\n",
    "\"\"\"WARNING: Make sure you specify a unique, informative, and concise name for the training job.\"\"\"\n",
    "od_model.fit(inputs=data_channels, logs=True, job_name = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41131aa",
   "metadata": {},
   "source": [
    "# Visualizing Results from a Training Job (Wait Until Training Job is Complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eefd39",
   "metadata": {},
   "source": [
    "### Regardless of whether you tuned a model or trained a model, training jobs will have been created. The following code chunks help visualize a training job's results. Note that you can close this notebook and stop the notebook instance, and you will still be able to run this code to visualize results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd0a90",
   "metadata": {},
   "source": [
    "Now that we have trained a model, we can take a look at the Mean Average Precision (mAP) score to assess how the training job progressed on the validation data. Below is code to plot the mAP against what appears to be the epochs with the best mAP scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39138d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Specifying the training log channel\n",
    "client = boto3.client(\"logs\")\n",
    "BASE_LOG_NAME = \"/aws/sagemaker/TrainingJobs\"\n",
    "\n",
    "# Function to plot the mAP score over time against the epochs\n",
    "def plot_object_detection_log(model, title):\n",
    "    logs = client.describe_log_streams(\n",
    "        logGroupName=BASE_LOG_NAME, logStreamNamePrefix=model\n",
    "    )\n",
    "    cw_log = client.get_log_events(\n",
    "        logGroupName=BASE_LOG_NAME, logStreamName=logs[\"logStreams\"][0][\"logStreamName\"]\n",
    "    )\n",
    "\n",
    "    mAP_accs = []\n",
    "    for e in cw_log[\"events\"]:\n",
    "        msg = e[\"message\"]\n",
    "        if \"validation mAP <score>=\" in msg:\n",
    "            num_start = msg.find(\"(\")\n",
    "            num_end = msg.find(\")\")\n",
    "            mAP = msg[num_start + 1 : num_end]\n",
    "            mAP_accs.append(float(mAP))\n",
    "\n",
    "    print(title)\n",
    "    print(\"Maximum mAP: %f \" % max(mAP_accs))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Mean Avg Precision (mAP)\")\n",
    "    (val_plot,) = ax.plot(range(len(mAP_accs)), mAP_accs, label=\"mAP\")\n",
    "    plt.legend(handles=[val_plot])\n",
    "    ax.yaxis.set_ticks(np.arange(0.0, 1.05, 0.1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%0.2f\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to plot mAP score against epochs\n",
    "\n",
    "\"\"\"Specify the name of the training job you want to produce a plot for.\"\"\"\n",
    "training_job_name = \"\"\n",
    "plot_object_detection_log(training_job_name, \"mAP tracking for job: \" + training_job_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
