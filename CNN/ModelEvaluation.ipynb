{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217aca61",
   "metadata": {},
   "source": [
    "# This notebook uses the spectrograms in the \"data/\" directory (and a trained model from the S3 Bucket) to assess model performance and predict the locations of vocalizations in WAV files. These predictions are stored in TXT files (which are formatted as Raven Selection Tables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e5ddd",
   "metadata": {},
   "source": [
    "#### Change the name of the S3 Bucket (wherever it appears in the code) to reflect the name of the S3 Bucket in your AWS Account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f572f2",
   "metadata": {},
   "source": [
    "#### Do not move any import statements to different code chunks. The code seems to break if the import statements are moved around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed8534",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccf5e9",
   "metadata": {},
   "source": [
    "The first set of import statements (others will be introduced as they are needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450331d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.io import wavfile\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "import re\n",
    "import json\n",
    "import sagemaker\n",
    "import glob\n",
    "from sagemaker import get_execution_role, session\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf028c6",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f817c28",
   "metadata": {},
   "source": [
    "Specifies the paths to the directories in the S3 Bucket which contain models and training jobs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e6bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Name of the S3 Bucket where model artifacts are located\n",
    "    # NOTE: Change \"bucket_name\" to the name of the S3 Bucket for your AWS account.\n",
    "    # (Note that part of the current name has been redacted for privacy.)\n",
    "bucket_name = \"sagemaker-us-...\"\n",
    "\n",
    "# Files and Directories\n",
    "MODEL_OUTPUT_URL = f\"s3://{bucket_name}/output\"\n",
    "BASE_LOG_NAME = \"/aws/sagemaker/TrainingJobs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba6e07",
   "metadata": {},
   "source": [
    "Specifies the \"default\" values for the post-processing of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT VALUES FOR POST-PROCESSING (Feel Free to Modify)\n",
    "DEFAULT_OVERLAP_THRESH = 0\n",
    "DEFAULT_CONF_TYPE = \"Relative\"\n",
    "DEFAULT_CONF_THRESH = 85\n",
    "DEFAULT_FREQ_LIM = None\n",
    "DEFAULT_IoU_THRESH = 0.2\n",
    "DEFAULT_DESIRED_CLASSES = [\"hb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc132d6",
   "metadata": {},
   "source": [
    "Maps class names to their class numbers (and vice versa) for model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS ID MAPPING for Model's Predictions (Make sure it reflects the data that the model was trained on)\n",
    "PRED_CLASS_ID_MAP = {\"blank\": 0, \"hb\": 1,\"kw\": 2, \"rf\": 3, \"sl\": 4}\n",
    "PRED_CLASS_NAME_MAP = {0: \"blank\", 1: \"hb\", 2: \"kw\", 3: \"rf\", 4: \"sl\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96853091",
   "metadata": {},
   "source": [
    "Maps class names to their class numbers (and vice versa) for hand annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544bc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS ID MAPPING for hand-annotations (Make sure it reflects the data in the \"data/\" directory)\n",
    "HAND_CLASS_ID_MAP = {\"blank\": 0, \"hb\": 1, \"kw\": 2, \"rf\": 3, \"sl\": 4}\n",
    "HAND_CLASS_NAME_MAP = {0: \"blank\", 1: \"hb\", 2: \"kw\", 3: \"rf\", 4: \"sl\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1a6d3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c0dcb",
   "metadata": {},
   "source": [
    "### Models and Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140e85e",
   "metadata": {},
   "source": [
    "Allows this notebook to properly interface with the rest of SageMaker and access the S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a996a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establishes the SageMaker session and determines the region in which the session is occurring\n",
    "sm_session = sagemaker.Session()\n",
    "region = sm_session.boto_region_name\n",
    "\n",
    "# Specifies the execution role to establish permissions for access purposes\n",
    "role = get_execution_role()\n",
    "\n",
    "# Obtains the necessary information in order to invoke the model endpoint later\n",
    "runtime = boto3.client(service_name=\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd58a37",
   "metadata": {},
   "source": [
    "Defines a function that can obtain a trained model from the S3 Bucket (assuming the corresponding training job has finished training the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3919128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris\n",
    "\n",
    "def get_model_from_output(model_output_path):\n",
    "    \"\"\"\n",
    "    Function to obtain a model's artifacts (i.e., the file containing the information needed to use the model).\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        model_output_path: string\n",
    "            The directory corresponding to the name of the model's training job (see the initalization of \"model_url\" for more details).\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        model: \"Model\" object\n",
    "            \"A SageMaker Model that can be deployed to an Endpoint\"\n",
    "                (https://sagemaker.readthedocs.io/en/stable/api/inference/model.html)\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    model_url = f\"s3://{bucket_name}/output/{model_output_path}/output/model.tar.gz\"\n",
    "    # Retrieves the URI to the object detection docker image\n",
    "    image_uri = image_uris.retrieve(\n",
    "        region=sm_session.boto_region_name, framework=\"object-detection\", version=\"latest\")\n",
    "\n",
    "    model = Model(image_uri=image_uri, model_data=model_url, role=role)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293d0bd",
   "metadata": {},
   "source": [
    "Defines a function that can delete a model endpoint.\n",
    "This function must be called once you are done using the model endpoint to avoid excessive charges to the AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24219f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model(model):\n",
    "    \"\"\"\n",
    "    Function to delete model endpoint.\n",
    "    RUN THIS AS SOON AS YOU ARE DONE USING THE ENDPOINT TO AVOID ADDITIONAL CHARGES TO THE AWS ACCOUNT!\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        model: \"Model\" object\n",
    "            A SageMaker model currently deployed to a SageMaker endpoint.\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        N/A\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    print(model)\n",
    "    print(f\"endpoint_name - {model.endpoint_name}\")\n",
    "    cur_name = model.endpoint_name\n",
    "    # Causes error for unknown reason\n",
    "    #cur_name = str(model.endpoint_name)\n",
    "    endpoint_config_name = re.sub(\"endpoint/\", \"endpoint-config/\", cur_name)\n",
    "    \n",
    "    sagemaker.Session().delete_endpoint_config(model.endpoint_name)\n",
    "    sagemaker.Session().delete_endpoint(model.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd751fe",
   "metadata": {},
   "source": [
    "Defines a function that can create a SageMaker endpoint to host and use the model. It also deploys the model to that endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcba5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "def deploy_model(model, endpoint_name):\n",
    "    \"\"\"\n",
    "    Deploys the model to a SageMaker endpoint with the name specified by \"endpoint_name\".\n",
    "    Takes roughly 10 minutes to fully create the endpoint from a notebook instance using the \"ml.t3.medium\" instance type.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        model: \"Model\" object\n",
    "            A SageMaker model created by \"get_model_from_output()\".\n",
    "        endpoint_name: string\n",
    "            The name of the endpoint you would like to create.\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        predictor: \"callable[string, sagemaker.session.Session] or None\"\n",
    "            (https://sagemaker.readthedocs.io/en/stable/api/inference/model.html)\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    print(\"EndpointName={}\".format(endpoint_name))\n",
    "    \n",
    "    try:\n",
    "        data_capture_config = DataCaptureConfig(\n",
    "        enable_capture=True, sampling_percentage=100, destination_s3_uri=MODEL_OUTPUT_URL)\n",
    "\n",
    "        predictor = model.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type=\"ml.m4.xlarge\",\n",
    "            endpoint_name=endpoint_name,\n",
    "            data_capture_config=data_capture_config,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        delete_model(model)\n",
    "        return deploy_model()\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab720a1",
   "metadata": {},
   "source": [
    "The second set of import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c3538a",
   "metadata": {},
   "source": [
    "Defines a function that can print information about an endpoint's predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3c62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import time\n",
    "\n",
    "def get_predictor(endpoint_name):\n",
    "    \"\"\"\n",
    "    Gets the predictor based on the name of the created endpoint.\n",
    "        NOTE: This function does not serve a critical purpose. It exists only so we can print and observe the predictor.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        endpoint_name: string\n",
    "            The name of an endpoint that currently exists.\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        predictor: \"Predictor\" object\n",
    "            (https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html)\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5e955",
   "metadata": {},
   "source": [
    "### IoU Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0fc39",
   "metadata": {},
   "source": [
    "Defines and tests a function that can calculate the IoU (Intersection over Union) between two bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be63add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    ----------\n",
    "\n",
    "    RETURNS\n",
    "    ----------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    assert bb1['x1'] <= bb1['x2']\n",
    "    assert bb1['y1'] <= bb1['y2']\n",
    "    assert bb2['x1'] <= bb2['x2']\n",
    "    assert bb2['y1'] <= bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    #print(bb1, bb2)\n",
    "    try:\n",
    "        iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Two bounding boxes with a nonpositive dimension found. Treating IoU as 0.\")\n",
    "        iou = 0\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c59b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests get_iou() function\n",
    "box1 = {\"x1\": 0.1, \"x2\": 0.2, \"y1\": 0.2, \"y2\": 0.8}\n",
    "box2 = {\"x1\": 0.1, \"x2\": 0.3, \"y1\": 0.2, \"y2\": 0.7}\n",
    "get_iou(box1, box2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391ddd8",
   "metadata": {},
   "source": [
    "### Post-Processing Strategies (for Filtering Predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afacef",
   "metadata": {},
   "source": [
    "Defines a function that can apply NMS (Non=Maximum Suppression) to a list of model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b351072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nms_pred_filter(preds, nms_thresh = DEFAULT_OVERLAP_THRESH):\n",
    "    \"\"\"\n",
    "    Filters out all but the highest-confidence predicted bounding box in cases where multiple predicted boxes for the same class overlap \n",
    "    (using Non-Maximum Suppression Algorithm) to improve overall quality of predictions.\n",
    "        *SOURCE: https://towardsdatascience.com/non-maximum-suppression-nms-93ce178e177c\n",
    "        \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score)\n",
    "            (Note that each predicted box includes information on its confidence score, so we \n",
    "                do not need a separate list to hold the confidence scores.)\n",
    "                    \n",
    "        nms_thresh: float\n",
    "            Represents the maximum overlap predicted boxes will be \"allowed\" to have before NMS is applied.\n",
    "    ----------\n",
    "        \n",
    "    RETURNS\n",
    "    ----------\n",
    "        filt_preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score) after applying the NMS threshold\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Handles situation where the NMS Threshold is set to None\n",
    "    if nms_thresh is None:\n",
    "        return preds\n",
    "    \n",
    "    # Implements NMS Algorithm\n",
    "    filt_preds = []\n",
    "    while len(preds) > 0:\n",
    "        bad_preds = []\n",
    "        # Step 1:\n",
    "        max_conf_score_pred = preds.pop(0)\n",
    "        filt_preds.append(max_conf_score_pred)\n",
    "        # Step 2:\n",
    "        klass_max, score_max, x0_max, y0_max, x1_max, y1_max = max_conf_score_pred\n",
    "        box_max = {\"x1\": x0_max, \"x2\": x1_max, \"y1\": y0_max,\"y2\": y1_max}\n",
    "        for i, predBox in enumerate(preds):\n",
    "            klass, score, x0, y0, x1, y1 = predBox\n",
    "            box = {\"x1\": x0, \"x2\": x1, \"y1\": y0,\"y2\": y1}\n",
    "            iou = get_iou(box_max, box)\n",
    "\n",
    "            if iou > nms_thresh and klass_max == klass:\n",
    "                bad_preds.append(predBox)\n",
    "                \n",
    "        for i, predBox in enumerate(bad_preds):\n",
    "            # \"Normal\" NMS Technique\n",
    "            preds.remove(predBox)\n",
    "            # \"Soft-NMS\" Technique\n",
    "            #preds[i][1] = preds[i][1]*(1-iou)\n",
    "                \n",
    "    return filt_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6bdc88",
   "metadata": {},
   "source": [
    "Defines a function that can apply a relative confidence threshold to a list of model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9eafe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rel_conf_subset(preds, pctl):\n",
    "    \"\"\"\n",
    "    Implements relative confidence threshold, based on the percentile (with respect to confidence score) \n",
    "    of predicted boxes to keep.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score)\n",
    "            \n",
    "        pctl: float\n",
    "            Percentile (based on confidence score) of predicted boxes to keep\n",
    "            (Example: \"pctl = 90\" refers to the set of predicted bounding boxes with confidence scores in the 90th percentile)\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score) after applying the relative confidence threshold\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Handles situation where the Relative Confidence Threshold is set to None\n",
    "    if pctl is None:\n",
    "        return preds\n",
    "    \n",
    "    # Discards all but the top \"100-pctl\" percent of predictions (with respect to their confidence score)\n",
    "    toTake = len(preds)*(1-pctl/100)\n",
    "    preds = preds[:int(toTake)]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94032dc",
   "metadata": {},
   "source": [
    "Defines a function that can apply a frequency limit to a model's humpback whale predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75216a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def limit_box_frequency(preds, freq_cutoff = DEFAULT_FREQ_LIM):\n",
    "    \"\"\"\n",
    "    Removes predicted bounding boxes (for humpback whales) that exclusively exist above a specific frequency (in Hz).\n",
    "    (Example: If freq_cutoff is 1000 Hz, every box that exclusively exists above 1000 Hz on its spectrogram is removed \n",
    "        from the list of predictions.)\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score)\n",
    "            \n",
    "        freq_cutoff: float\n",
    "            Upper limit for a box's lower frequency bound (in Hz)\n",
    "            (Note that, if the box's lower frequency bound is above a specific frequency, the entire box is located above that frequency.)\n",
    "    ----------\n",
    "            \n",
    "    RETURNS\n",
    "    ----------\n",
    "        filt_preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score) after applying the frequency limit\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Handles situation where the Frequency Limit is set to None\n",
    "    if freq_cutoff is None:\n",
    "        return preds\n",
    "    \n",
    "    # This is the y-axis's maximum frequency on the spectrograms.\n",
    "        # NOTE: This number is related to the value specified for \"FREQUENCY_MAX\" in \"ConvertWavToSpec.ipynb\".\n",
    "            # For example, SPEC_MAX_FREQ = 1455.749312 when \"FREQUENCY_MAX\" = 1600\n",
    "            # See the comments within \"convert_pred_spec_coords_to_wav_coords()\" for more details on how to determine this value.\n",
    "    SPEC_MAX_FREQ = 1455.749312\n",
    "    # Converts the frequency cutoff value into a form that can be compared to the coordinates of a bounding box\n",
    "        # *NOTE: Subtraction occurs because a y-coordinate of 0 reflects the top of the spectrogram (while a y-coordinate of 1 reflects the bottom)\n",
    "    freq_cutoff = 1 - freq_cutoff/SPEC_MAX_FREQ\n",
    "    filt_preds = []\n",
    "    for i, predBox in enumerate(preds):\n",
    "        klass, score, x0, y0, x1, y1 = predBox\n",
    "        # \"Less than\" is used because a y-coordinate of 0 reflects the top of the spectrogram (while a y-coordinate of 1 reflects the bottom)\n",
    "        if y1 < freq_cutoff and klass == PRED_CLASS_ID_MAP[\"hb\"]:\n",
    "            continue\n",
    "        # Adds predicted boxes that are not \"too high\" to the filtered list of predictions\n",
    "        filt_preds.append(predBox)\n",
    "        \n",
    "    return filt_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abb735",
   "metadata": {},
   "source": [
    "Defines an experimental function that can combine overlapping model predictions for the same species into one big prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec4d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_overlaps(preds, overlap_thresh = None):\n",
    "    \"\"\"\n",
    "    NOTE: Code has not been tested in a while (writing this message on 7/23/22). Be wary of using it.\n",
    "    \n",
    "    EXPERIMENTAL STRATEGY: Combines two bounding boxes into one big box (if they exceed the overlap threshold) and keeps the \n",
    "    higher of the two confidence scores.\n",
    "        *NOTE: This does not seem to improve performance, so I do not recommend using this as one of the post-processing steps.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        preds: sorted list of predicted boxes (sorted by confidence score)\n",
    "            *Note that each predicted box includes information on its confidence score, so we do not need a separate list to \n",
    "            hold the confidence scores.\n",
    "            \n",
    "        overlap_thresh: a float that represents the maximum overlap predicted boxes will be \"allowed\" to have\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        filt_preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score) after applying the overlap threshold\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Handles situation where the Overlap Threshold is set to None\n",
    "    if overlap_thresh is None:\n",
    "        return preds\n",
    "    \n",
    "    filt_preds = []\n",
    "    while len(preds) > 0:\n",
    "        bad_preds = []\n",
    "        # Takes prediction with maximum confidence and removes it from \"preds\"\n",
    "        max_conf_score_pred = preds.pop(0)\n",
    "        # Extracts important information from the maximum-confidence prediction\n",
    "        klass_max, score_max, x0_max, y0_max, x1_max, y1_max = max_conf_score_pred\n",
    "        # Reformats the bounding box information to be compatible with get_iou()\n",
    "        box_max = {\"x1\": x0_max, \"x2\": x1_max, \"y1\": y0_max, \"y2\": y1_max}\n",
    "        # Iterates through all remaining predictions in \"preds\"\n",
    "        for i, predBox in enumerate(preds):\n",
    "            # Extracts and reformats same information as before, but for a predicted box that remains in \"preds\"\n",
    "            klass, score, x0, y0, x1, y1 = predBox\n",
    "            box = {\"x1\": x0, \"x2\": x1, \"y1\": y0, \"y2\": y1}\n",
    "            # Calculates IoU between the max-confidence box and a box currently in \"preds\"\n",
    "            iou = get_iou(box_max, box)\n",
    "            # If the iou score between the two boxes exceeds the overlap threshold, combines the two boxes and keeps the higher confidence score\n",
    "            if iou > overlap_thresh and klass_max == klass:\n",
    "                # Adds lower-confidence box to list of \"bad\" predictions to be deleted from \"preds\" later\n",
    "                bad_preds.append(predBox)\n",
    "                # Boxes are combined into one big box by updating coordinates\n",
    "                new_x0 = min(box_max['x1'], box['x1'])\n",
    "                new_x1 = max(box_max['x2'], box['x2'])\n",
    "                new_y0 = min(box_max['y1'], box['y1'])\n",
    "                new_y1 = max(box_max['y2'], box['y2'])\n",
    "                # The higher-confidence prediction gets these new coordinates\n",
    "                max_conf_score_pred[2] = new_x0\n",
    "                max_conf_score_pred[3] = new_y0\n",
    "                max_conf_score_pred[4] = new_x1\n",
    "                max_conf_score_pred[5] = new_y1\n",
    "                # Updates the bounding box information for the higher-confidence prediction so that IoU continues to be properly calculated.\n",
    "                box_max = {\"x1\": new_x0, \"x2\": new_x1, \"y1\": new_y0, \"y2\": new_y1}\n",
    "        # Bad predictions are removed from \"preds\"\n",
    "        for i, predBox in enumerate(bad_preds):\n",
    "            preds.remove(predBox)\n",
    "        # The combined box, now with the highest confidence out of the original overlapping boxes, is added to the filtered list of predictions\n",
    "        filt_preds.append(max_conf_score_pred)\n",
    "    return filt_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71cf86",
   "metadata": {},
   "source": [
    "Defines the function that filters model predictions using post-processing strategies and the list of desired classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(preds, overlap_threshold = DEFAULT_OVERLAP_THRESH, conf_type = DEFAULT_CONF_TYPE, \n",
    "                       conf_threshold = DEFAULT_CONF_THRESH, FREQ_LIM = DEFAULT_FREQ_LIM, desired_classes = DEFAULT_DESIRED_CLASSES):\n",
    "    \"\"\"\n",
    "    Applies various \"post-processing\" strategies to remove \"bad\" predictions from the list of predicted bounding boxes.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score)\n",
    "            \n",
    "        overlap_threshold: float\n",
    "            One of the \"post-processing\" parameters (i.e., parameters that help remove \"bad\" predictions)\n",
    "            \n",
    "        conf_type: string\n",
    "            Specifies which type of \"confidence threshold\" with be used in post-processing\n",
    "            \n",
    "        conf_threshold: float\n",
    "            One of the \"post-processing\" parameters\n",
    "            \n",
    "        FREQ_LIM: float\n",
    "            One of the \"post-processing\" parameters\n",
    "            \n",
    "        desired_classes: list of strings \n",
    "            Specifies class names whose predictions should be returned\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score) for the desired classes after applying all post-processing steps\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Obtains only the desired predictions\n",
    "    old_preds = preds\n",
    "    preds = []\n",
    "    for i, predBox in enumerate(old_preds):\n",
    "        klass, score, x0, y0, x1, y1 = predBox\n",
    "        # Uses list of desired classes\n",
    "        for i in desired_classes:\n",
    "            if klass == PRED_CLASS_ID_MAP[i]:\n",
    "                preds.append(predBox)\n",
    "\n",
    "                \n",
    "    # Implements relative confidence threshold, based on the percentile (with respect to confidence score) of predicted boxes to keep\n",
    "    if conf_type == \"Relative\":\n",
    "        preds = rel_conf_subset(preds, conf_threshold)\n",
    "    # Implements Absolute Confidence Threshold (not desirable compared to relative confidence threshold)\n",
    "    #if conf_type == \"Absolute\":\n",
    "        #preds = [preds[i] for i in range(len(preds)) if preds[i][1] >= conf_threshold]\n",
    "    \n",
    "    # Filters out \"bad\" predictions using Non-Maximum Suppression (NMS)\n",
    "    preds = nms_pred_filter(preds, overlap_threshold)\n",
    "    \n",
    "    # Removes predicted bounding boxes that exclusively exist above a specific frequency (in Hz)\n",
    "    #preds = limit_box_frequency(preds, FREQ_LIM)\n",
    "    \n",
    "    # Combines overlapping predicted boxes into one big box\n",
    "    #preds = combine_overlaps(preds, 0)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2574c",
   "metadata": {},
   "source": [
    "### Using an endpoint to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4303918b",
   "metadata": {},
   "source": [
    "Defines the function that uses the model endpoint to make predictions on a single spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58a914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_bounding_boxes(spectrogram_name, overlap_threshold = DEFAULT_OVERLAP_THRESH, conf_type = DEFAULT_CONF_TYPE, \n",
    "                             conf_threshold = DEFAULT_CONF_THRESH, FREQ_LIM = DEFAULT_FREQ_LIM, desired_classes = DEFAULT_DESIRED_CLASSES):\n",
    "    \"\"\"\n",
    "    Gets the list of model predictions (using the model's endpoint created by \"deploy_model()\") for a single spectrogram and \n",
    "    calls \"filter_preds()\".\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        spectrogram_name: string\n",
    "            File path to the current spectrogram (saved as a .png file) that the model should predict on\n",
    "            \n",
    "        overlap_threshold: float\n",
    "            One of the \"post-processing\" parameters (i.e., parameters that help remove \"bad\" predictions)\n",
    "            \n",
    "        conf_type: string\n",
    "            Specifies which type of \"confidence threshold\" with be used in post-processing\n",
    "            \n",
    "        conf_threshold: float\n",
    "            One of the \"post-processing\" parameters\n",
    "            \n",
    "        FREQ_LIM: float\n",
    "            One of the \"post-processing\" parameters\n",
    "            \n",
    "        desired_classes: list of strings \n",
    "            Specifies class names whose predictions you want\n",
    "    ----------\n",
    "        \n",
    "    RETURNS\n",
    "    ----------\n",
    "        preds: list of lists\n",
    "            Contains predicted boxes (sorted by confidence score) for the desired classes after applying all post-processing steps\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    \n",
    "    # Uses the model endpoint to predict where vocalizations are on the current spectrogram (and gets those predictions)\n",
    "    try:\n",
    "        with open(spectrogram_name, \"rb\") as image:\n",
    "            f = image.read()\n",
    "            b = bytearray(f)\n",
    "\n",
    "            endpoint_response = runtime.invoke_endpoint(EndpointName=predictor.endpoint_name, ContentType=\"image/png\", Body=b)\n",
    "            results = endpoint_response[\"Body\"].read()\n",
    "            detections = json.loads(results)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    # Sorting predicted bounding boxes by confidence score (descending order)\n",
    "    preds = sorted(detections[\"prediction\"], key=lambda x:x[1], reverse=True)\n",
    "    # Applies various post-processing strategies to remove \"bad\" predictions\n",
    "    preds = filter_predictions(preds, \n",
    "                               overlap_threshold = overlap_threshold, \n",
    "                               conf_type = conf_type, \n",
    "                               conf_threshold = conf_threshold, \n",
    "                               FREQ_LIM = FREQ_LIM,\n",
    "                               desired_classes = desired_classes)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd5c3e",
   "metadata": {},
   "source": [
    "### Getting desired hand-annotations from a LST File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35791c9",
   "metadata": {},
   "source": [
    "Defines the function that uses a LST file to obtain desired hand-annotations for a single spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad82b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hand_annotated_boxes_spec(spec_name, lst_name, desired_classes = DEFAULT_DESIRED_CLASSES):\n",
    "    \"\"\"\n",
    "    Gets the desired hand-annotations for the relevant spectrogram (from the relevant LST file).\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        spec_name: string\n",
    "            The name of the spectrogram that you want hand-annotations for (as it appears in the LST file)\n",
    "        \n",
    "        lst_name: string\n",
    "            The name of the LST file containing the hand-annotations\n",
    "        \n",
    "        desired_classes: list of strings\n",
    "            Contains the class names that you want hand-annotations for\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        temp: list of lists\n",
    "            Contains the desired hand-annotations for the spectrogram specified by \"spec_name\"\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    with open(lst_name, \"r\") as f:\n",
    "        for line in f:\n",
    "            filePath = line.split(\"\\t\")[-1]\n",
    "            fileName = filePath.split(\"/\")[-1].strip()\n",
    "            \n",
    "            if spec_name == fileName:\n",
    "                annots = [float(el) for el in line.split(\"\\t\")[3:-1]]\n",
    "                # Keeps classes number in box information\n",
    "                temp = [annots[i:i+5] for i in range(0, len(annots), 5)]\n",
    "                \n",
    "                # FILTERS HAND ANNOTATIONS TO ONLY CONTAIN DESIRED ANNOTATIONS\n",
    "                if temp is not None:\n",
    "                    old_hand_annots = temp\n",
    "                    temp = []\n",
    "                    for i, handAnnot in enumerate(old_hand_annots):\n",
    "                        klass_true, xmin, ymin, xmax, ymax = handAnnot\n",
    "                        for i in desired_classes:\n",
    "                            if klass_true == HAND_CLASS_ID_MAP[i]:\n",
    "                                temp.append(handAnnot)    \n",
    "                \n",
    "                return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cfa4a0",
   "metadata": {},
   "source": [
    "### Visualizing Predictions and Hand-Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ea261",
   "metadata": {},
   "source": [
    "Defines the functions which allow you to visualize the hand-annotations and a model's predictions on the relevant spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38a356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "from time import sleep\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def plot_hand_annotations(hand_annots, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Plots a spectrogram's hand-annotated boxes on the spectrogram\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        hand_annots: list of lists\n",
    "            Contains the hand-annotations you want to display on the spectrogram\n",
    "            \n",
    "        img_height: int\n",
    "            The height of the image\n",
    "            \n",
    "        img_width: int\n",
    "            The width of the image\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        N/A\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Iterates through every hand-annotation in the list\n",
    "    for index, annot in enumerate(hand_annots):\n",
    "        # Obtains important box information and uses it to plot the hand-annotated box\n",
    "        klass, x0, y0, x1, y1 = annot\n",
    "        \n",
    "        xmin = int(x0 * img_width)\n",
    "        ymin = int(y0 * img_height)\n",
    "        xmax = int(x1 * img_width)\n",
    "        ymax = int(y1 * img_height)\n",
    "        rect1 = plt.Rectangle(\n",
    "                    (xmin, ymin),\n",
    "                    xmax - xmin,\n",
    "                    ymax - ymin,\n",
    "                    fill=False,\n",
    "                    edgecolor=\"red\",\n",
    "                    linewidth=3.5,\n",
    "                    label = \"Hand-Annotated\"\n",
    "                )\n",
    "        plt.gca().add_patch(rect1)\n",
    "        \n",
    "        # Colors the box differently depending on which class it represents\n",
    "        if klass == 0:\n",
    "            col = 'blue'\n",
    "        if klass == 1:\n",
    "            col = 'pink'\n",
    "        if klass == 2:\n",
    "            col = 'green'\n",
    "        if klass == 3:\n",
    "            col = 'yellow'\n",
    "        if klass == 4:\n",
    "            col = 'black'\n",
    "        \n",
    "        plt.gca().text(\n",
    "            xmin,\n",
    "            ymin - 3,\n",
    "            f\"{index}\",\n",
    "            bbox=dict(facecolor=col, alpha=0.5),\n",
    "            fontsize=10,\n",
    "            color=\"white\",\n",
    "        )\n",
    "\n",
    "def plot_model_predicted_boxes(predicted_boxes, img_height, img_width, thresh=0.2):\n",
    "    \"\"\"\n",
    "    Plots a spectrogram's predicted boxes on the spectrogram\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        predicted_boxes: list of lists \n",
    "            Contains the predictions you want to display on the spectrogram\n",
    "            \n",
    "        img_height: int\n",
    "            The height of the image\n",
    "            \n",
    "        img_width: int\n",
    "            The width of the image\n",
    "            \n",
    "        thresh: float\n",
    "            The minimum confidence score a prediction must have to be plotted.\n",
    "            (NOTE: The code that implements \"thresh\" is currently commented out since the list of predictions \n",
    "                is typically filtered before the call to this function.)\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        num_detections: int\n",
    "            The total number of predictions plotted on the spectrogram.\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    num_detections = 0\n",
    "    for index, det in enumerate(predicted_boxes):\n",
    "        (klass, score, x0, y0, x1, y1) = det\n",
    "        \n",
    "        #if score < thresh:\n",
    "            #continue\n",
    "        num_detections += 1\n",
    "        xmin = int(x0 * img_width)\n",
    "        ymin = int(y0 * img_height)\n",
    "        xmax = int(x1 * img_width)\n",
    "        ymax = int(y1 * img_height)\n",
    "        rect2 = plt.Rectangle(\n",
    "            (xmin, ymin),\n",
    "            xmax - xmin,\n",
    "            ymax - ymin,\n",
    "            fill=False,\n",
    "            edgecolor='yellow',\n",
    "            linewidth=3.5,\n",
    "            label=\"Model-Predicted\"\n",
    "        )\n",
    "        plt.gca().add_patch(rect2)\n",
    "        plt.gca().text(\n",
    "            xmin,\n",
    "            ymin - 3,\n",
    "            f\"{index}, {round(score, 2)}\",\n",
    "            bbox=dict(facecolor='orange', alpha=0.5),\n",
    "            fontsize=10,\n",
    "            color=\"white\",\n",
    "        )\n",
    "    \n",
    "    return num_detections\n",
    "        \n",
    "\n",
    "def plot_image_with_boxes(filename, hand_annotated_boxes=None, model_predicted_boxes=None, threshold=0.2, pctl=80):\n",
    "    \"\"\"\n",
    "    Plots a single spectrogram and also provides the option of displaying the bounding boxes for its annotations.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        filename: string\n",
    "            Represents the file path to the spectrogram\n",
    "            \n",
    "        hand-annotated_boxes: list of lists (optional)\n",
    "            Contains the hand-annotations you want to display on the spectrogram \n",
    "                (or is None, if you don't want to display any hand-annotations)\n",
    "                \n",
    "        model_predicted_boxes: list of lists (optional) \n",
    "            Contains the predictions you want to display on the spectrogram \n",
    "                (or is None, if you don't want to display any predictions)\n",
    "                \n",
    "        threshold: float\n",
    "            The minimum confidence score a prediction must have to be plotted.\n",
    "            (NOTE: The code that implements \"thresh\" is currently commented out since the list of predictions \n",
    "                is typically filtered before the call to this function.)\n",
    "                \n",
    "        pctl: float\n",
    "            Represents the percentile of predictions which are kept after applying \"threshold\"\n",
    "            Note that, because the code for applying \"threshold\" is currently commented out, \n",
    "                I typically pass in a value of 0 for the percentile \n",
    "                (even if a different percentile was applied before the call to this function).\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        N/A\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Reads in the spectrogram and initializes important specifications\n",
    "    plt.close()\n",
    "    figure(figsize=(20, 15), dpi=150)\n",
    "    img = mpimg.imread(filename)\n",
    "    plt.imshow(img)\n",
    "    img_height = img.shape[0]\n",
    "    print(img_height)\n",
    "    img_width = img.shape[1]\n",
    "    print(img_width)\n",
    "    colors = dict()\n",
    "    num_detections = 0\n",
    "    classes=[]\n",
    "    \n",
    "    # Plots the model's predicted bounding bounding boxes on the spectrogram (if the corresponding list was passed in as a parameter)\n",
    "    if model_predicted_boxes:\n",
    "        num_detections = plot_model_predicted_boxes(model_predicted_boxes, img_height, img_width, threshold)\n",
    "        \n",
    "    # Plots the hand-annotated bounding boxes on the spectrogram (if the corresponding list was passed in as a parameter)\n",
    "    if(hand_annotated_boxes):\n",
    "        plot_hand_annotations(hand_annotated_boxes, img_height, img_width)\n",
    "        \n",
    "    # Prints important information and adds axes to the spectrogram\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    print(\"Number of detections: \" + str(num_detections))\n",
    "    \n",
    "    # Adds a different title to the spectrogram depending on what is plotted\n",
    "    if hand_annotated_boxes and model_predicted_boxes:\n",
    "        title = f\"Spectrogram {filename} \\n with Hand-Annotations and Predictions\"\n",
    "        #title = f\"Spectrogram with Predictions Above\\nthe {pctl}th Percentile\"\n",
    "    elif hand_annotated_boxes:\n",
    "        title = f\"Spectrogram {filename} \\n Hand-Annotated Boxes\"\n",
    "    else:\n",
    "        title = f\"Spectrogram {filename} \\n\"\n",
    "\n",
    "    plt.title(title, fontdict={'fontsize':24})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c6d2b",
   "metadata": {},
   "source": [
    "### Defines a helpful function that produces a list containing the file path to each spectrogram in the \"data/\" directory (sorted by beginning time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ceace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_spec_paths(wav_fname, files = glob.glob('data/*.png')):\n",
    "    \"\"\"\n",
    "    Given a single WAV file name, produces a sorted list containing the file path for each of its spectrograms.\n",
    "        (This assumes \"ConvertWavToSpec.ipynb\" has already placed the WAV file's spectrograms in the \"data/\" directory.)\n",
    "        (Furthermore, this also assumes that no audio chunks were \"skipped over\" during spectrogram creation.)\n",
    "            (For example, if spectrograms were removed for lacking annotations, the corresponding audio chunks were \"skipped over\".)\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        wav_fname: string\n",
    "            Denotes the \"numeric\" portion of the WAV file's name (e.g., wav_fname = \"671658014.181008033412\")\n",
    "            \n",
    "        files: list of strings\n",
    "            An unsorted list containing all spectrogram file paths for the WAV file specified by \"wav_fname\"\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        all_spec_paths: list of strings\n",
    "            A sorted list containing all spectrogram file paths for the WAV file specified by \"wav_fname\"\n",
    "            (Note that the spectrogram file paths are sorted by the beginning times they correspond to in the WAV file)\n",
    "                (e.g., all_spec_paths = \n",
    "                    [\"data/671658014.181008033412-0.png\", \"data/671658014.181008033412-1.png\", \"data/671658014.181008033412-2.png\", ...])\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    all_spec_paths = []\n",
    "    for file in files:\n",
    "        cur_name = file.split(\"/\")[-1]\n",
    "        if wav_fname in cur_name:\n",
    "            cur_name = \"data/\" + cur_name.split(\"-\")[0] + \"-\" + str(len(all_spec_paths)) + \".png\"\n",
    "            all_spec_paths.append(cur_name)\n",
    "    return all_spec_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4337f4b",
   "metadata": {},
   "source": [
    "## Getting a Previously-Trained Model and Deploying it to a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c6e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gets model artifacts from S3 Bucket\n",
    "    # Example: model_path = \"cpbio-final-best-model\"\n",
    "model_path = \"cpbio-final-best-model\"\n",
    "model = get_model_from_output(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d77446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the name of the endpoint you want to create\n",
    "endpoint_name = \"modelendpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bad887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates endpoint that will be used for model evaluation\n",
    "    # Note that you may encounter an error upon running this code chunk. If so, simply run this code chunk again.\n",
    "\"\"\"\n",
    "The endpoint takes roughly 10 minutes to create. When the creation process is complete, the output should look similar to the following:\n",
    "\n",
    "    EndpointName=modelendpoint\n",
    "    ---------------!\n",
    "    \n",
    "\"\"\"\n",
    "deploy_model(model, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef8cc1",
   "metadata": {},
   "source": [
    "#### Wait until the endpoint has been created before running any more code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints technical model information\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets and prints the endpoint's predictor\n",
    "predictor = get_predictor(endpoint_name)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f324661",
   "metadata": {},
   "source": [
    "## Specifying Post-Processing Parameters and Location of Hand-Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b491e6",
   "metadata": {},
   "source": [
    "This code chunk allows you to specify the post-processing parameters (and the LST file containing the hand-annotations) for any performance evaluations or prediction files you produce. Feel free to modify these values and rerun the code chunk if you want to try different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da49825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Use either Relative Confidence Thresholds or Absolute Confidence Thresholds, but never both.\n",
    "# NOTE: I recommend keeping all but one parameter to a single value in the lists (in order to avoid excessive runtimes).\n",
    "\n",
    "# Non-Maximum Suppression (NMS) Thresholds (list)\n",
    "overlap_thresholds = [0]\n",
    "#overlap_thresholds = [None]\n",
    "\n",
    "# Relative Confidence Thresholds (list)\n",
    "conf_thresholds = [85]\n",
    "#conf_thresholds = [None]\n",
    "conf_type = \"Relative\"\n",
    "# Absolute Confidence Thresholds (list)\n",
    "#conf_thresholds = [0.225]\n",
    "#conf_type = \"Absolute\"\n",
    "\n",
    "# Frequency Limit, measured in Hz\n",
    "FREQ_LIM = None\n",
    "\n",
    "# IoU Threshold\n",
    "iou_threshold = 0.2\n",
    "\n",
    "# Desired classes (list of strings)\n",
    "    # Specify each class name you desire predictions and performance metrics for \n",
    "    # Type the name as it is written in \"Allowed Classes\" from ConvertWavToSpec.ipynb\n",
    "#desired_classes = [\"blank\", \"hb\", \"kw\", \"rf\", \"sl\"]\n",
    "desired_classes = [\"hb\"]\n",
    "\n",
    "#LST file that you want hand-annotations from\n",
    "lst_file_name = \"val.lst\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89167d37",
   "metadata": {},
   "source": [
    "#### Now, different code chunks need to be run depending on whether you want to calculate performance metrics, produce a selection table of predicted annotations for use in Raven, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2eaf2",
   "metadata": {},
   "source": [
    "## Calculating Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e3d44",
   "metadata": {},
   "source": [
    "Defines the function that determines the number of true positives, false positives, and false negatives between a set of predictions and a set of hand-annotations. These values are necessary to calculate precision and recall later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d41e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_precision_recall(predicted_boxes, hand_annotated_boxes, iou_threshold = DEFAULT_IoU_THRESH):\n",
    "    \"\"\"\n",
    "    Calculates the number of true positives, false positives, and false negatives for a list of predictions and a list of hand-annotations.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        predicted_boxes: list of lists\n",
    "            Contains the predictions which will be used in the performance evaluation\n",
    "            \n",
    "        hand_annotated_boxes: list of lists\n",
    "            Contains the hand-annotations which will be used in the performance evaluation\n",
    "            \n",
    "        iou_threshold: float \n",
    "            Determines the minimum amount of overlap that a predicted box must have with a hand-annotated box in order to be a \n",
    "                successful prediction.\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        truePositives: int\n",
    "            The number of predicted boxes in \"predicted_boxes\" that have enough overlap with a hand-annotated box in \"hand_annotated_boxes\"\n",
    "            (Note that two predicted boxes can have enough overlap with the same hand-annotated box, and this counts as two true positives.)\n",
    "            \n",
    "        falsePositives: int\n",
    "            The number of predicted boxes in \"predicted_boxes\" that do not have enough overlap with a hand-annotated box in \n",
    "                \"hand_annotated_boxes\".\n",
    "                \n",
    "        falseNegatives: int\n",
    "            The number of hand-annotated boxes in \"hand_annotated_boxes\" that do not have enough overlap with a predicted box in \n",
    "                \"predicted_boxes\".\n",
    "                \n",
    "        predicted_boxes: list of lists\n",
    "            The final list of predicted boxes\n",
    "            \n",
    "        numberHandAnnotated: int\n",
    "            The total number of hand-annotations within \"hand_annotated_boxes\"\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    truePositives = 0\n",
    "    falsePositives = 0\n",
    "    \n",
    "    # Catches the cases when there are no hand-annotations\n",
    "    if hand_annotated_boxes is None:\n",
    "        truePositives = 0\n",
    "        falsePositives = len(predicted_boxes)\n",
    "        falseNegatives = 0\n",
    "        return truePositives, falsePositives, falseNegatives, predicted_boxes, 0\n",
    "    \n",
    "    # Creates a \"notVisited\" list that tracks which hand annotations have been \"visited\" by a prediction (and initializes each status to True)\n",
    "    notVisited = [True for box in hand_annotated_boxes]\n",
    "    numberHandAnnotated = len(hand_annotated_boxes)\n",
    "\n",
    "    # Creates various lists (some of which are currently unused)\n",
    "    maxIouScores = []\n",
    "    boxes = []\n",
    "    flags = [False for box in predicted_boxes]\n",
    "    \n",
    "    \n",
    "    ### Original Implementation of Absolute Confidence Threshold\n",
    "        ### NOTE: Currently hardcoded at 0.225; precision increases when applying the threshold elsewhere for unknown reason.\n",
    "    #predicted_boxes = [predicted_boxes[i] for i in range(len(predicted_boxes)) if predicted_boxes[i][1] >= 0.225]\n",
    "    \n",
    "    \n",
    "    ### Likely the Original Implementation of Relative Confidence Threshold\n",
    "        ### NOTE: Currently hardcoded at 90th percentile\n",
    "        ### NOTE: Relative Confidence Thresholds can now be applied in filter_predictions(), but the option to do it here remains.\n",
    "    ###pctl = 90\n",
    "    ###toTake = len(predicted_boxes)*(1-pctl/100)\n",
    "    ###predicted_boxes = predicted_boxes[:int(toTake)]\n",
    "    \n",
    "    \n",
    "    # Catches the cases when there are no predictions\n",
    "    if len(predicted_boxes) == 0:\n",
    "        truePositives = 0\n",
    "        falsePositives = 0\n",
    "        falseNegatives = numberHandAnnotated\n",
    "        return truePositives, falsePositives, falseNegatives, predicted_boxes, numberHandAnnotated\n",
    "    \n",
    "    # Finds each prediction's \"max IoU\" across all hand-annotations and adds each max IoU to a list (currently serves no purpose)\n",
    "    for i, predBox in enumerate(predicted_boxes):\n",
    "        klass, score, x0, y0, x1, y1 = predBox\n",
    "\n",
    "        maxIou = None\n",
    "        for j, handAnnot in enumerate(hand_annotated_boxes):\n",
    "            klass_true, xmin, ymin, xmax, ymax = handAnnot\n",
    "            predictedBox = {\"x1\": x0, \"x2\": x1, \"y1\": y0,\"y2\": y1}\n",
    "            groundTruth = {\"x1\": xmin, \"x2\": xmax,\"y1\": ymin,\"y2\": ymax}\n",
    "            iouScore = get_iou(predictedBox, groundTruth)\n",
    "            \n",
    "            if maxIou is None or iouScore > maxIou:\n",
    "                maxIou = iouScore\n",
    "        maxIouScores.append(maxIou)\n",
    "    \n",
    "    # Calculates the number of True Positives, False Positives, and False Negatives across every prediction and hand-annotation\n",
    "    # Iterates through every prediction in the list\n",
    "    for i, predBox in enumerate(predicted_boxes):\n",
    "        # Gets important information from the current prediction\n",
    "        klass, score, x0, y0, x1, y1 = predBox\n",
    "        # Initializes the current prediction's \"count\" status to False (meaning it does not \"count\" as a True Positive)\n",
    "        count = False\n",
    "        # Iterates through every hand-annotation in the list\n",
    "        for j, handAnnot in enumerate(hand_annotated_boxes):\n",
    "            # Gets important information from the current hand-annotation\n",
    "            klass_true, xmin, ymin, xmax, ymax = handAnnot   \n",
    "            # Properly formats the predicted box's information and hand-annotated box's information to be input for \"get_iou()\"\n",
    "            predictedBox = {\"x1\": x0, \"x2\": x1, \"y1\": y0,\"y2\": y1}\n",
    "            groundTruth = {\"x1\": xmin, \"x2\": xmax,\"y1\": ymin,\"y2\": ymax}\n",
    "            # Calculates the IoU between the current predicted box and current hand-annotated box\n",
    "            iouScore = get_iou(predictedBox, groundTruth)\n",
    "            # Checks if the prediction and hand-annotation have \"enough\" overlap and belong to the same class\n",
    "            if iouScore > iou_threshold and PRED_CLASS_NAME_MAP[klass] == HAND_CLASS_NAME_MAP[klass_true]:\n",
    "                # If so, the prediction \"counts\" as a success, and the hand-annotation has been \"visited\" by a prediction.\n",
    "                count = True\n",
    "                notVisited[j] = False\n",
    "\n",
    "        # After comparing the current prediction to every hand-annotation, the prediction's status is evaluated\n",
    "        if count:\n",
    "            # If it was \"counted\" during any comparison, then we consider it a True Positive.\n",
    "            truePositives += 1\n",
    "        else:\n",
    "            # If it was never \"counted\", then we consider it a False Positive.\n",
    "            falsePositives += 1\n",
    "    # After checking every combination of a prediction and hand-annotation, any \"unvisited\" hand-annoations are False Negatives\n",
    "    falseNegatives = sum(notVisited)\n",
    "    return truePositives, falsePositives, falseNegatives, predicted_boxes, numberHandAnnotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c4abc",
   "metadata": {},
   "source": [
    "Defines and calls the function that evaluates the model's performance on all spectrograms in the \"data/\" directory. If there are no spectrograms in the \"data/\" directory, use ConvertWavToSpec.ipynb to create some. You can specify different values for the post-processing parameters to see how they impact precision and recall. The runtime of this function depends on the number of spectrograms and parameter values used in the performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d596be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this chunk when you want to test your model on the spectrograms in the \"data/\" directory. \n",
    "# It will output performance metrics, and you can specify post-processing parameters.\n",
    "\n",
    "# Gets the file path to each PNG file in the \"data/\" directory\n",
    "files = glob.glob('data/*.png')\n",
    "\n",
    "# Function to test your model and obtain evaluation metrics.\n",
    "def get_metrics(files, overlap_thresholds = [DEFAULT_OVERLAP_THRESH], \n",
    "                conf_type = DEFAULT_CONF_TYPE, conf_thresholds = [DEFAULT_CONF_THRESH], \n",
    "                FREQ_LIM = DEFAULT_FREQ_LIM, iou_threshold = DEFAULT_IoU_THRESH, \n",
    "                desired_classes = DEFAULT_DESIRED_CLASSES, lst_file_name = \"val.lst\"):\n",
    "    \"\"\"\n",
    "    For every combination of NMS threshold and Confidence threshold, calculates the model's performance metrics across every spectrogram \n",
    "    in \"files\".\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        files: list of strings \n",
    "            Denotes the path to each PNG file (i.e., each spectrogram) that should be considered in the performance evaluation\n",
    "            \n",
    "        overlap_thresholds: list of floats \n",
    "            Denotes the NMS thresholds you wish to apply in post-processing (one threshold per evaluation)\n",
    "            \n",
    "        conf_type: string\n",
    "            Either \"Relative\" or \"Absolute\".\n",
    "            Indicates whether you want your confidence thresholds to be interpreted as a \"relative\" confidence thresholds or \n",
    "                \"absolute\" confidence thresholds.\n",
    "            (NOTE: Support for \"absolute\" confidence thresholds has been commented out due to inconsistent performance \n",
    "                depending on where it is applied.)\n",
    "                \n",
    "        conf_thresholds: list of floats\n",
    "            Denotes the confidence thresholds you wish to apply in post-processing (one threshold per evaluation)\n",
    "            \n",
    "        FREQ_LIM: float\n",
    "            Denotes the frequency limit (in Hz) that you wish to apply in post-processing\n",
    "            \n",
    "        iou_threshold: float\n",
    "            Denotes the IoU threshold which determines the criteria for \"enough overlap\" between a predicted box and \n",
    "                a hand-annotated box.\n",
    "                \n",
    "        desired_classes: list of strings\n",
    "            Denotes the classes whose predictions and hand-annotations should be considered in the model evaluation\n",
    "            \n",
    "        lst_file_name: string\n",
    "            Specifies the name of the LST file which contains the hand-annotation information for the performance evaluation\n",
    "                (with the \".lst\" portion).\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        N/A\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    # Iterates across every combination of NMS threshold and Confidence threshold in the lists\n",
    "    for othresh in overlap_thresholds:\n",
    "        for cthresh in conf_thresholds:\n",
    "            # Initializes running totals\n",
    "            totalTp = 0\n",
    "            totalFp = 0\n",
    "            totalFn = 0\n",
    "            groundtruth = 0\n",
    "            # Prints important specifications for the current test\n",
    "            print(\"Model Name: \" + model_path)\n",
    "            print(f\"PERFORMANCE METRICS FOR {desired_classes} on {lst_file_name}\")\n",
    "            print(f\"NMS Overlap Threshold: {othresh}\")\n",
    "            print(f\"{conf_type} Confidence Threshold: {cthresh}\")\n",
    "            print(f\"Frequency Limit: {FREQ_LIM}\")\n",
    "            print(f\"IoU Threshold: {iou_threshold}\")\n",
    "            \n",
    "            # Iterates through every spectrogram file path in the list\n",
    "            for file in sorted(files):\n",
    "                spec_name = file.split(\"/\")[-1]\n",
    "                # Gets the list of desired hand-annotated boxes for the current spectrogram\n",
    "                hand_annotated_boxes = get_hand_annotated_boxes_spec(spec_name, lst_file_name, desired_classes)\n",
    "                \n",
    "                # Gets the post-processed list of desired predicted boxes for the current spectrogram\n",
    "                predictions = get_model_bounding_boxes(f\"data/{spec_name}\", \n",
    "                                                       overlap_threshold = othresh, \n",
    "                                                       conf_type = conf_type, \n",
    "                                                       conf_threshold = cthresh, \n",
    "                                                       FREQ_LIM = FREQ_LIM,\n",
    "                                                       desired_classes = desired_classes)\n",
    "                \n",
    "                # Obtains the number of true positives, false positives, false negatives, and hand-annotations for the current spectrogram\n",
    "                truePositives, falsePositives, falseNegatives, predicted_boxes, gt = calculate_precision_recall(predictions, \n",
    "                                                                                                                hand_annotated_boxes, \n",
    "                                                                                                                iou_threshold)\n",
    "                # Adds the number of true positives, false positives, false negatives, and hand-annotations to the running total\n",
    "                totalTp += truePositives\n",
    "                totalFp += falsePositives\n",
    "                totalFn += falseNegatives\n",
    "                groundtruth += gt\n",
    "                \n",
    "            # Calculates recall, precision, and f1-score across every spectrogram in \"files\"\n",
    "            try:\n",
    "                recall = (groundtruth-totalFn)/groundtruth\n",
    "            except ZeroDivisionError:\n",
    "                recall = \"Not Applicable\"\n",
    "                \n",
    "            try:\n",
    "                precision = totalTp/(totalTp + totalFp)\n",
    "            except ZeroDivisionError:\n",
    "                precision = \"Not Applicable\"\n",
    "                \n",
    "            try:\n",
    "                f1 = 2*(precision*recall)/(precision+recall)\n",
    "            except (TypeError, ZeroDivisionError) as error:\n",
    "                f1 = \"Not Applicable\"\n",
    "            \n",
    "            # Clearly displays results from the model evaluation\n",
    "            print(f\"   True Positives: {totalTp}, False Positives: {totalFp}, False Negatives: {totalFn}\")\n",
    "            print(f\"   Total Number of Predicted Boxes: {totalTp + totalFp}, Total Number of Hand-Annotated Boxes: {groundtruth}\")\n",
    "            print(f\"   Recall: {recall}\")\n",
    "            print(f\"   Precision: {precision}\")\n",
    "            print(f\"   F1 Score: {f1}\")\n",
    "            print()\n",
    "            print(\"Done!\")\n",
    "\n",
    "\n",
    "# Passes in spectrograms that will be evaluated, along with the evaluation parameters, and outputs evaluation metrics\n",
    "get_metrics(files = files, \n",
    "            overlap_thresholds = overlap_thresholds, \n",
    "            conf_type = conf_type, \n",
    "            conf_thresholds = conf_thresholds, \n",
    "            FREQ_LIM = FREQ_LIM, \n",
    "            iou_threshold = iou_threshold, \n",
    "            desired_classes = desired_classes,\n",
    "            lst_file_name = lst_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf419e",
   "metadata": {},
   "source": [
    "If there are a very small number of hand-annotations and predictions across the spectrograms, you can run the following code chunks to determine which spectrograms contain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd326347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all .png files from the \"data/\" directory\n",
    "files = glob.glob('data/*.png')\n",
    "\n",
    "# Specifies the name of the WAV file that you want to produce a selection table for\n",
    "wav_fname = \"671658014.181008033412\"\n",
    "#wav_fname = \"671658014.180930183532\"\n",
    "#wav_fname = \"671658014.181008003414\"\n",
    "#wav_fname = \"671658014.180929003601\"\n",
    "\n",
    "# Gets the path to every spectrogram for the WAV file (sorted in the proper order)\n",
    "all_spec_paths = get_all_spec_paths(wav_fname, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef060c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the names of spectrograms which have hand-annotations for the desired classes\n",
    "for i in all_spec_paths:\n",
    "    truth = get_hand_annotated_boxes_spec(i[5:], lst_file_name, desired_classes)\n",
    "    if len(truth) == 0:\n",
    "        continue\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the names of spectrograms which have model predictions (after post-processing)\n",
    "for i in all_spec_paths:\n",
    "    predictions = get_model_bounding_boxes(i, overlap_thresholds[0], conf_type, conf_thresholds[0], FREQ_LIM, desired_classes)\n",
    "    if len(predictions) == 0:\n",
    "        continue\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87c6e9",
   "metadata": {},
   "source": [
    "This code chunk plots the hand-annotations and predictions (from the model's performance evaluation) for a given spectrogram on that spectrogram. This is a highly recommended strategy for gauging how the model makes its decisions. You must specify the file name of the spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5089b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the desired, post-processed predicted boxes and desired hand-annotated boxes on the corresponding spectrogram (for a single spectrogram)\n",
    "filename = \"671658014.181008033412-0.png\"\n",
    "#filename = \"671658014.180930183532-0.png\"\n",
    "#filename = \"671658014.181008003414-0.png\"\n",
    "#filename = \"671658014.180929003601-0.png\"\n",
    "\n",
    "# Notice that the first post-processing value in each list is used.\n",
    "hand_annotated_boxes = get_hand_annotated_boxes_spec(filename, lst_file_name, desired_classes)\n",
    "predictions = get_model_bounding_boxes(f\"data/{filename}\", overlap_thresholds[0], conf_type, conf_thresholds[0], FREQ_LIM, desired_classes)\n",
    "print(predictions)\n",
    "plot_image_with_boxes(f\"data/{filename}\", hand_annotated_boxes=hand_annotated_boxes, model_predicted_boxes=predictions,\n",
    "                   threshold=0,pctl=conf_thresholds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b7dd1",
   "metadata": {},
   "source": [
    "This code chunk calculates performance metrics for a single spectrogram. You must specify the spectrogram's file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates performance metrics for a single spectrogram\n",
    "file_path = \"data/671658014.181008033412-0.png\"\n",
    "get_metrics(glob.glob(file_path), overlap_thresholds, conf_type, conf_thresholds, FREQ_LIM, iou_threshold, desired_classes, lst_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c130d7",
   "metadata": {},
   "source": [
    "This code chunk displays detailed information regarding a single spectrogram's predictions and hand-annotations. You must specify the file name of the spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff2c85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Displays the number of true positives, number of false positives, number of false negatives, \n",
    "list of predictions, and number of hand-annotations for a single spectrogram\n",
    "    NOTE: Uses the first NMS threshold and first Confidence threshold in the lists\n",
    "\"\"\"\n",
    "# Filename is the name of one of the spectrograms found in the data directory.\n",
    "# If there are no spectrograms in there, use ConvertWavToSpec.ipynb to generate some.\n",
    "    # Example: filename = \"671658014.181008033412-145.png\"\n",
    "filename = \"671658014.181008033412-0.png\"\n",
    "#filename = \"671658014.180930183532-0.png\"\n",
    "#filename = \"671658014.181008003414-0.png\"\n",
    "#filename = \"671658014.180929003601-0.png\"\n",
    "\n",
    "# Notice that the first post-processing value in each list is used.\n",
    "hand_annotated_boxes = get_hand_annotated_boxes_spec(filename, lst_file_name, desired_classes)\n",
    "predictions = get_model_bounding_boxes(f\"data/{filename}\", overlap_thresholds[0], conf_type, conf_thresholds[0], FREQ_LIM, desired_classes)\n",
    "calculate_precision_recall(predictions, hand_annotated_boxes, iou_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50cadd",
   "metadata": {},
   "source": [
    "## Producing a Selection Table of Predicted Annotations for Use in Raven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47f644",
   "metadata": {},
   "source": [
    "Useful Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8af47",
   "metadata": {},
   "source": [
    "Use this code chunk to specify and obtain important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all .png files from the \"data/\" directory\n",
    "files = glob.glob('data/*.png')\n",
    "\n",
    "# Specifies the name of the WAV file that you want to produce a selection table for\n",
    "wav_fname = \"671658014.181008033412\"\n",
    "#wav_fname = \"671658014.180930183532\"\n",
    "#wav_fname = \"671658014.181008003414\"\n",
    "#wav_fname = \"671658014.180929003601\"\n",
    "\n",
    "# Gets the path to every spectrogram for the WAV file (sorted in the proper order)\n",
    "all_spec_paths = get_all_spec_paths(wav_fname, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c7b300",
   "metadata": {},
   "source": [
    "Defines and calls the function that iterates through multiple spectrograms. It obtains predictions for each spectrogram and stores them in one large list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f85a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_bounding_boxes(all_spectrogram_paths, \n",
    "                                 overlap_threshold = DEFAULT_OVERLAP_THRESH, conf_type = DEFAULT_CONF_TYPE, \n",
    "                                 conf_threshold = DEFAULT_CONF_THRESH, FREQ_LIM = DEFAULT_FREQ_LIM, \n",
    "                                 desired_classes = DEFAULT_DESIRED_CLASSES):\n",
    "    \"\"\"\n",
    "    Gets the list of model predictions (using the model's endpoint created by \"deploy_model()\") for every spectrogram in \n",
    "    \"all_spectrogram_paths\". It is a shell that calls \"get_model_bounding_boxes()\" multiple times.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        all_spectrogram_paths: list of strings\n",
    "            Contains the file paths to the spectrograms that the model should make predictions for\n",
    "            \n",
    "        overlap_threshold: float\n",
    "            One of the \"post-processing\" parameters (i.e., parameters that help remove \"bad\" predictions)\n",
    "            \n",
    "        conf_type: string\n",
    "            Specifies which type of \"confidence threshold\" with be used in post-processing\n",
    "            \n",
    "        conf_threshold: float\n",
    "            One of the \"post-processing\" parameters\n",
    "            \n",
    "        FREQ_LIM: float\n",
    "            One of the \"post-processing\" parameters\n",
    "            \n",
    "        desired_classes: list of strings \n",
    "            Specifies class names whose predictions you want\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        all_preds: three-dimensional list \n",
    "            The list contains smaller lists (i.e., \"sublists\"), and each sublist contains predictions.\n",
    "                Each prediction is in the form of [klass, score, x0, y0, x1, y1].\n",
    "                Each sublist contains the desired, post-processed predicted boxes for the corresponding spectrogram.\n",
    "            Together, the sublists contain the predictions for every spectrogram in \"all_spectrogram_paths\".\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    for spectrogram_path in all_spectrogram_paths:\n",
    "        preds = get_model_bounding_boxes(spectrogram_path, \n",
    "                                         overlap_threshold = overlap_threshold, \n",
    "                                         conf_type = conf_type, \n",
    "                                         conf_threshold = conf_threshold, \n",
    "                                         FREQ_LIM = FREQ_LIM, \n",
    "                                         desired_classes = desired_classes)\n",
    "        all_preds.append(preds)\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c570b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the first post-processing value in each list is used.\n",
    "all_preds = get_all_model_bounding_boxes(all_spec_paths, overlap_thresholds[0], conf_type, conf_thresholds[0], FREQ_LIM, desired_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79865f75",
   "metadata": {},
   "source": [
    "Defines and calls the function that converts predicted box boundaries from being measured in terms of the spectrogram to being measured in terms of the entire WAV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ac925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pred_spec_coords_to_wav_coords(wav_fname, all_preds, time_span = 10800, chunk_size = 30, spec_overlap = 3.0, spec_max_freq = 1455.749312):\n",
    "    \"\"\"\n",
    "    Converts the location information for each predicted box in \"all_preds\" from being in terms of the spectrogram's edges (where all \n",
    "    location information is on a \"0 to 1\" scale) to being in terms of the entire WAV file (where \"time information\" can range across \n",
    "    the WAV file's full time span in seconds, and \"frequency information\" can range from 0 Hz to the maximum frequency visible on the \n",
    "    spectrograms.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        wav_fname: string\n",
    "            Contains the \"numeric\" portion of the WAV file's name (e.g., wav_fname = \"671658014.181008033412\")\n",
    "        \n",
    "        all_preds: three-dimensional list \n",
    "            The list contains smaller lists (i.e., \"sublists\"), and each sublist contains predictions.\n",
    "                Each prediction is in the form of [klass, score, x0, y0, x1, y1].\n",
    "                Each sublist contains the desired, post-processed predicted boxes for the corresponding spectrogram.\n",
    "            Together, the sublists contain the predictions for every spectrogram in \"all_spectrogram_paths\".\n",
    "                       \n",
    "        time_span: float\n",
    "            The elapsed time (in seconds) that the entire WAV file spans.\n",
    "            (EQUAL TO THE FINAL \"end_s\" PRINTED BY \"extract_chunk()\" WITHIN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "            \n",
    "        chunk_size: float\n",
    "            The amount of time (in seconds) that a single spectrogram covers.\n",
    "            (EQUAL TO \"CHUNK_SIZE_SEC\" WITHIN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "            \n",
    "        spec_overlap: float\n",
    "            The number of seconds of overlap between one spectrogram and its subsequent spectrogram.\n",
    "            (EQUAL TO THE FLOAT SPECIFIED IN \"int(<FLOAT> * sr)\" FOR THE CALCULATION OF \"step\" WITHIN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "            \n",
    "        spec_max_freq: float\n",
    "            The y-axis's maximum frequency on the spectrograms (in Hz)\n",
    "            (RELATED TO THE VALUE SPECIFIED FOR \"FREQUENCY_MAX\" IN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "                (Example: spec_max_freq = 1455.749312 when FREQUENCY_MAX = 1600)\n",
    "            (Currently, the only way to determine the exact value is to cross-reference hand-annotated boxes with the annotation TXT file.)\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        conv_preds: list of lists\n",
    "            A list of predictions that correspond to those in \"all_preds\" with converted location information \n",
    "                (i.e., the format for a predicted box is [klass, score, beg_time, end_time, min_freq, max_freq] instead of [klass, score, x0, y0, x1, y1])\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    conv_preds = []\n",
    "    for i, cur_preds in enumerate(all_preds):\n",
    "        \n",
    "        start_of_spec = (chunk_size - spec_overlap)*i\n",
    "        if i == len(all_preds)-1 and i > 0:\n",
    "            length_of_spec = time_span - start_of_spec\n",
    "        else:\n",
    "            length_of_spec = chunk_size\n",
    "        \n",
    "        for pred in cur_preds:\n",
    "            klass, score, x0, y0, x1, y1 = pred\n",
    "        \n",
    "            beg_time = start_of_spec + x0*length_of_spec\n",
    "            end_time = start_of_spec + x1*length_of_spec\n",
    "            min_freq = (1-y1)*spec_max_freq\n",
    "            max_freq = (1-y0)*spec_max_freq\n",
    "        \n",
    "            cur_conv_pred = [klass, score, beg_time, end_time, min_freq, max_freq]\n",
    "            conv_preds.append(cur_conv_pred)\n",
    "    return conv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_preds = convert_pred_spec_coords_to_wav_coords(wav_fname, all_preds, 10799.5225, 30, 3.0, 1455.749312)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe36c93",
   "metadata": {},
   "source": [
    "Defines and calls the function that creates a selection table (in the form of a TXT file) containing all desired predictions for a specified WAV file. This selection table can be opened in Raven alongside the WAV file, allowing you to \"listen\" to the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4df4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_selection_table(wav_fname, conv_preds):\n",
    "    \"\"\"\n",
    "    Makes a TXT file reflecting the model's predictions for the specified WAV file (called \"<wav_fname>-predictions.txt\").\n",
    "    It will be formatted very similarly to the annotators' TXT files for use in Raven as a selection table.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        wav_fname: string\n",
    "            The \"numeric\" portion of the WAV file's name (e.g., wav_fname = \"671658014.181008033412\")\n",
    "            \n",
    "        conv_preds: list of lists\n",
    "            A list of all predictions for the specified WAV file.\n",
    "                Each prediction is in the form of [klass, score, beg_time, end_time, min_freq, max_freq].\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        N/A\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    column_names = [\"Selection\", \"View\", \"Channel\", \"Begin Time (s)\", \"End Time (s)\", \"Low Freq (Hz)\", \"High Freq (Hz)\", \"Species\", \"Confidence Score\"]\n",
    "    \n",
    "    # Removes old TXT file with same name (if one exists)\n",
    "    file_name = f\"{wav_fname}-predictions.txt\"\n",
    "    if exists(file_name):\n",
    "        print(f\"{file_name} exists, removing now\")\n",
    "        !rm $file_name\n",
    "    \n",
    "    # Creates TXT file\n",
    "    with open(f\"{wav_fname}-predictions.txt\", \"a\") as f:\n",
    "        for col in column_names:\n",
    "            f.write(col)\n",
    "            if col == column_names[-1]:\n",
    "                continue\n",
    "            f.write('\\t')\n",
    "        f.write('\\n')\n",
    "        \n",
    "        for i, pred in enumerate(conv_preds):\n",
    "            \n",
    "            f.write(str(i+1))\n",
    "            f.write('\\t')\n",
    "            f.write(\"Spectrogram 1\")\n",
    "            f.write('\\t')\n",
    "            f.write('1')\n",
    "            f.write('\\t')\n",
    "            \n",
    "            klass, score, beg_time, end_time, min_freq, max_freq = pred\n",
    "            f.write(str(beg_time))\n",
    "            f.write('\\t')\n",
    "            f.write(str(end_time))\n",
    "            f.write('\\t')\n",
    "            f.write(str(min_freq))\n",
    "            f.write('\\t')\n",
    "            f.write(str(max_freq))\n",
    "            f.write('\\t')\n",
    "            f.write(PRED_CLASS_NAME_MAP[klass])\n",
    "            f.write('\\t')\n",
    "            f.write(str(score))\n",
    "            \n",
    "            f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_selection_table(wav_fname, conv_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d424b",
   "metadata": {},
   "source": [
    "## CLEANUP (After Evaluating a Model or Producing a Prediction TXT File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91704f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"RUN THIS CODE CHUNK WHEN YOU ARE DONE USING THE ENDPOINT TO AVOID ADDITIONAL CHARGES TO THE ACCOUNT\"\"\"\n",
    "delete_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d9306",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e61abd5",
   "metadata": {},
   "source": [
    "Useful (but currently unused) function that can download anything from the S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the S3 Bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defines the function\n",
    "def fetch_from_bucket(source_file_path, dest_file_name):\n",
    "    bucket.download_file(source_file_path, dest_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1557d10",
   "metadata": {},
   "source": [
    "Currently unused code that creates a selection table of hand-annotations for use in Raven. This is redundant since the resulting files should be identical to our annotation files, but this allows us to verify that our code works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a680c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all .png files from the \"data/\" directory\n",
    "files = glob.glob('data/*.png')\n",
    "# Specifies the name of the WAV file that you want to produce a selection table for\n",
    "wav_fname = \"671658014.181008033412\"\n",
    "#wav_fname = \"671658014.180930183532\"\n",
    "#wav_fname = \"671658014.181008003414\"\n",
    "#wav_fname = \"671658014.180929003601\"\n",
    "\n",
    "# Gets the path to every spectrogram for the WAV file (sorted in the proper order)\n",
    "all_spec_paths = get_all_spec_paths(wav_fname, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_hand_annotated_boxes_spec(all_spectrogram_paths, lst_file_name, desired_classes):\n",
    "    \"\"\"\n",
    "    Gets the list of hand annotations (from the specified LST file) for every spectrogram in \n",
    "    \"all_spectrogram_paths\". It is a shell that calls \"get_hand_annotated_boxes_spec()\" multiple times.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        all_spectrogram_paths: list of strings\n",
    "            Contains the file paths to the spectrograms that the model should make predictions for\n",
    "\n",
    "        lst_file_name: string\n",
    "            Specifies the name of the LST file which contains the hand-annotation information for the performance evaluation\n",
    "                (with the \".lst\" portion).\n",
    "            \n",
    "        desired_classes: list of strings \n",
    "            Specifies class names whose predictions you want\n",
    "    ----------\n",
    "    \n",
    "    RETURNS\n",
    "    ----------\n",
    "        all_hand_annots: three-dimensional list \n",
    "            The list contains smaller lists (i.e., \"sublists\"), and each sublist contains hand-annotations.\n",
    "                Each hand-annotation is in the form of [klass, x0, y0, x1, y1].\n",
    "                Each sublist contains the hand-annotations for the corresponding spectrogram.\n",
    "            Together, the sublists contain the hand-annotations for every spectrogram in \"all_spectrogram_paths\".\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    all_hand_annots = []\n",
    "    for spectrogram_path in all_spectrogram_paths:\n",
    "        spec_name = spectrogram_path.split(\"/\")[-1]\n",
    "        hand_annots = get_hand_annotated_boxes_spec(spec_name, \n",
    "                                                    lst_file_name, \n",
    "                                                    desired_classes = desired_classes)\n",
    "        all_hand_annots.append(hand_annots)\n",
    "    return all_hand_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hand_annots = get_all_hand_annotated_boxes_spec(all_spec_paths, lst_file_name, desired_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc19d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hand_spec_coords_to_wav_coords(wav_fname, all_hand_annots, time_span = 10800, chunk_size = 30, spec_overlap = 3.0, spec_max_freq = 1455.749312):\n",
    "    \"\"\"\n",
    "    Converts the location information for each hand-annotated box in \"all_hand_annots\" from being in terms of the spectrogram's edges (where all \n",
    "    location information is on a \"0 to 1\" scale) to being in terms of the entire WAV file (where \"time information\" can range across \n",
    "    the WAV file's full time span in seconds, and \"frequency information\" can range from 0 Hz to the maximum frequency visible on the \n",
    "    spectrograms.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        wav_fname: string\n",
    "            Contains the \"numeric\" portion of the WAV file's name (e.g., wav_fname = \"671658014.181008033412\")\n",
    "        \n",
    "        all_hand_annots: three-dimensional list \n",
    "            The list contains smaller lists (i.e., \"sublists\"), and each sublist contains hand-annotations.\n",
    "                Each hand-annotation is in the form of [klass, x0, y0, x1, y1].\n",
    "                Each sublist contains the desired, post-processed hand-annotated boxes for the corresponding spectrogram.\n",
    "            Together, the sublists contain the hand-annotations for every spectrogram in \"all_spectrogram_paths\".\n",
    "                       \n",
    "        time_span: float\n",
    "            The elapsed time (in seconds) that the entire WAV file spans.\n",
    "            (EQUAL TO THE FINAL \"end_s\" PRINTED BY \"extract_chunk()\" WITHIN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "            \n",
    "        chunk_size: float\n",
    "            The amount of time (in seconds) that a single spectrogram covers.\n",
    "            (EQUAL TO \"CHUNK_SIZE_SEC\" WITHIN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "            \n",
    "        spec_overlap: float\n",
    "            The number of seconds of overlap between one spectrogram and its subsequent spectrogram.\n",
    "            (EQUAL TO THE FLOAT SPECIFIED IN \"int(<FLOAT> * sr)\" FOR THE CALCULATION OF \"step\" WITHIN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "            \n",
    "        spec_max_freq: float\n",
    "            The y-axis's maximum frequency on the spectrograms (in Hz)\n",
    "            (RELATED TO THE VALUE SPECIFIED FOR \"FREQUENCY_MAX\" IN \"ConvertWavToSpec.ipynb\" WHEN THE SPECTROGRAMS WERE CREATED)\n",
    "                (Example: spec_max_freq = 1455.749312 when FREQUENCY_MAX = 1600)\n",
    "            (Currently, the only way to determine the exact value is to cross-reference hand-annotated boxes with the annotation TXT file.)\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        conv_hand_annots: list of lists\n",
    "            A list of hand-annotations that correspond to those in \"all_hand_annots\" with converted location information \n",
    "                (i.e., the format for a hand-annotated box is [klass, beg_time, end_time, min_freq, max_freq] instead of [klass, x0, y0, x1, y1])\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    conv_hand_annots = []\n",
    "    for i, cur_hand_annots in enumerate(all_hand_annots):\n",
    "        \n",
    "        start_of_spec = (chunk_size - spec_overlap)*i\n",
    "        if i == len(all_hand_annots)-1:\n",
    "            length_of_spec = time_span - start_of_spec\n",
    "        else:\n",
    "            length_of_spec = chunk_size\n",
    "            \n",
    "        for hand_annot in cur_hand_annots:\n",
    "            klass, x0, y0, x1, y1 = hand_annot\n",
    "        \n",
    "            beg_time = start_of_spec + x0*length_of_spec\n",
    "            end_time = start_of_spec + x1*length_of_spec\n",
    "            min_freq = (1-y1)*spec_max_freq\n",
    "            max_freq = (1-y0)*spec_max_freq\n",
    "        \n",
    "            cur_conv_hand_annot = [klass, beg_time, end_time, min_freq, max_freq]\n",
    "            conv_hand_annots.append(cur_conv_hand_annot)\n",
    "    return conv_hand_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90072a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_hand_annots = convert_hand_spec_coords_to_wav_coords(wav_fname, all_hand_annots, 10799.5225, 30, 3.0, 1455.749312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_selection_table(wav_fname, conv_preds):\n",
    "    \"\"\"\n",
    "    Makes a TXT file reflecting the model's hand-annotations for the specified WAV file (called \"<wav_fname>-hands.txt\").\n",
    "    It will be formatted very similarly to the annotators' TXT files for use in Raven as a selection table.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "        wav_fname: string\n",
    "            The \"numeric\" portion of the WAV file's name (e.g., wav_fname = \"671658014.181008033412\")\n",
    "            \n",
    "        conv_hand_annots: list of lists\n",
    "            A list of all hand-annotations for the specified WAV file.\n",
    "                Each hand-annotation is in the form of [klass, beg_time, end_time, min_freq, max_freq].\n",
    "    ----------\n",
    "    \n",
    "    RETURNS:\n",
    "    ----------\n",
    "        N/A\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    column_names = [\"Selection\", \"View\", \"Channel\", \"Begin Time (s)\", \"End Time (s)\", \"Low Freq (Hz)\", \"High Freq (Hz)\", \"Species\"]\n",
    "    \n",
    "    # Removes old TXT file with same name (if one exists)\n",
    "    file_name = f\"{wav_fname}-hands.txt\"\n",
    "    if exists(file_name):\n",
    "        print(f\"{file_name} exists, removing now\")\n",
    "        !rm $file_name\n",
    "    \n",
    "    with open(f\"{wav_fname}-hands.txt\", \"a\") as f:\n",
    "        for col in column_names:\n",
    "            f.write(col)\n",
    "            if col == column_names[-1]:\n",
    "                continue\n",
    "            f.write('\\t')\n",
    "        f.write('\\n')\n",
    "        \n",
    "        for i, hand_annot in enumerate(conv_hand_annots):\n",
    "            \n",
    "            f.write(str(i+1))\n",
    "            f.write('\\t')\n",
    "            f.write(\"Spectrogram 1\")\n",
    "            f.write('\\t')\n",
    "            f.write('1')\n",
    "            f.write('\\t')\n",
    "            \n",
    "            klass, beg_time, end_time, min_freq, max_freq = hand_annot\n",
    "            f.write(str(beg_time))\n",
    "            f.write('\\t')\n",
    "            f.write(str(end_time))\n",
    "            f.write('\\t')\n",
    "            f.write(str(min_freq))\n",
    "            f.write('\\t')\n",
    "            f.write(str(max_freq))\n",
    "            f.write('\\t')\n",
    "            f.write(HAND_CLASS_NAME_MAP[klass])\n",
    "            \n",
    "            f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_selection_table(wav_fname, conv_hand_annots)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "21f1c44619812e16b21b01da5e7dc3aeec474b5c3ef8a100f50268ae295817b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
